{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanlucjackson/w266_final_project/blob/main/code/inference/awesome_T5_pt_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh-4vVXTMhpC"
      },
      "source": [
        "### Generate Predictions From An Awesome Validation Dataset\n",
        "\n",
        "This notebook assumes a T5 PyTorch model.\n",
        "\n",
        "Setting the constants in the next call should be all that is necessary to run the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rlCLzceMMahp"
      },
      "outputs": [],
      "source": [
        "# Set these constants for each model and validation dataset combination\n",
        "\n",
        "model_name = \"T5_base_pt_long.triviaqa\"\n",
        "validation_dataset_names = [\"nq\", \"quac\", \"squad\", \"triviaqa\"]\n",
        "\n",
        "save_predictions = True\n",
        "save_mode = 'w' # w for write, a for append\n",
        "\n",
        "max_input_length = 1024\n",
        "\n",
        "num_beams = 4\n",
        "no_repeat_ngram_size = 3\n",
        "max_target_length = 50\n",
        "min_target_length = 1\n",
        "early_stopping = True\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "start_sample = None  # If None, then 0 will be used\n",
        "end_sample = None # If None, then the end of the set will be used"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ8lW8X8NJ9o"
      },
      "source": [
        "### Generate Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c3906UT0dyke"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vBX23WXdd0v-"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17N1XaF7d6dW",
        "outputId": "b8c04cf7-ea1f-4aeb-ff15-ac27d974bd7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3jvE9TJRd4cG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#from google.colab import data_table\n",
        "#data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iMHoUiDnd9He"
      },
      "outputs": [],
      "source": [
        "# Some important file locations and constants\n",
        "\n",
        "project_root = \"/content/drive/MyDrive/w266 NLP Final Project/\"\n",
        "#project_root = \"/home/localadmin/Documents/w266_NLP_Final_Project/\"\n",
        "dataset_root = project_root + \"Data/\"\n",
        "model_root = project_root + \"Models/\"\n",
        "prediction_folder = project_root + \"Predictions/checkpoint/\"\n",
        "\n",
        "tokenizer = \"google/t5-v1_1-base\"\n",
        "model_folder = model_root + model_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fEhqOalVycI9"
      },
      "outputs": [],
      "source": [
        "# Get the model and tokenizer\n",
        "\n",
        "T5_tokenizer = T5Tokenizer.from_pretrained(tokenizer)\n",
        "T5_model = T5ForConditionalGeneration.from_pretrained(model_folder)\n",
        "T5_model.to(torch.device('cuda:0'))\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYAIRZMxwXNn",
        "outputId": "d41ce696-a8ca-4e6a-ed00-f21ff6c2ff4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/w266 NLP Final Project/Data/nq/valid_pairs.csv\n",
            "Generating predictions using nq from 0 to 2356:\n",
            "25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 800 825 850 875 900 925 950 975 1000 \n",
            "1025 1050 1075 1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525 1550 1575 1600 1625 1650 1675 1700 1725 1750 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000 \n",
            "2025 2050 2075 2100 2125 2150 2175 2200 2225 2250 2275 2300 2325 2350 2356 \n",
            "Predictions generated.\n",
            "Write: /content/drive/MyDrive/w266 NLP Final Project/Predictions/checkpoint/predictions.T5_base_pt_long.triviaqa.nq.csv\n",
            "/content/drive/MyDrive/w266 NLP Final Project/Data/quac/valid_pairs.csv\n",
            "Generating predictions using quac from 0 to 5868:\n",
            "25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 800 825 850 875 900 925 950 975 1000 \n",
            "1025 1050 1075 1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525 1550 1575 1600 1625 1650 1675 1700 1725 1750 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000 \n",
            "2025 2050 2075 2100 2125 2150 2175 2200 2225 2250 2275 2300 2325 2350 2375 2400 2425 2450 2475 2500 2525 2550 2575 2600 2625 2650 2675 2700 2725 2750 2775 2800 2825 2850 2875 2900 2925 2950 2975 3000 \n",
            "3025 3050 3075 3100 3125 3150 3175 3200 3225 3250 3275 3300 3325 3350 3375 3400 3425 3450 3475 3500 3525 3550 3575 3600 3625 3650 3675 3700 3725 3750 3775 3800 3825 3850 3875 3900 3925 3950 3975 4000 \n",
            "4025 4050 4075 4100 4125 4150 4175 4200 4225 4250 4275 4300 4325 4350 4375 4400 4425 4450 4475 4500 4525 4550 4575 4600 4625 4650 4675 4700 4725 4750 4775 4800 4825 4850 4875 4900 4925 4950 4975 5000 \n",
            "5025 5050 5075 5100 5125 5150 5175 5200 5225 5250 5275 5300 5325 5350 5375 5400 5425 5450 5475 5500 5525 5550 5575 5600 5625 5650 5675 5700 5725 5750 5775 5800 5825 5850 5868 \n",
            "Predictions generated.\n",
            "Write: /content/drive/MyDrive/w266 NLP Final Project/Predictions/checkpoint/predictions.T5_base_pt_long.triviaqa.quac.csv\n",
            "/content/drive/MyDrive/w266 NLP Final Project/Data/squad.hf/valid_pairs.csv\n",
            "Generating predictions using squad from 0 to 10570:\n",
            "25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 800 825 850 875 900 925 950 975 1000 \n",
            "1025 1050 1075 1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525 1550 1575 1600 1625 1650 1675 1700 1725 1750 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000 \n",
            "2025 2050 2075 2100 2125 2150 2175 2200 2225 2250 2275 2300 2325 2350 2375 2400 2425 2450 2475 2500 2525 2550 2575 2600 2625 2650 2675 2700 2725 2750 2775 2800 2825 2850 2875 2900 2925 2950 2975 3000 \n",
            "3025 3050 3075 3100 3125 3150 3175 3200 3225 3250 3275 3300 3325 3350 3375 3400 3425 3450 3475 3500 3525 3550 3575 3600 3625 3650 3675 3700 3725 3750 3775 3800 3825 3850 3875 3900 3925 3950 3975 4000 \n",
            "4025 4050 4075 4100 4125 4150 4175 4200 4225 4250 4275 4300 4325 4350 4375 4400 4425 4450 4475 4500 4525 4550 4575 4600 4625 4650 4675 4700 4725 4750 4775 4800 4825 4850 4875 4900 4925 4950 4975 5000 \n",
            "5025 5050 5075 5100 5125 5150 5175 5200 5225 5250 5275 5300 5325 5350 5375 5400 5425 5450 5475 5500 5525 5550 5575 5600 5625 5650 5675 5700 5725 5750 5775 5800 5825 5850 5875 5900 5925 5950 5975 6000 \n",
            "6025 6050 6075 6100 6125 6150 6175 6200 6225 6250 6275 6300 6325 6350 6375 6400 6425 6450 6475 6500 6525 6550 6575 6600 6625 6650 6675 6700 6725 6750 6775 6800 6825 6850 6875 6900 6925 6950 6975 7000 \n",
            "7025 7050 7075 7100 7125 7150 7175 7200 7225 7250 7275 7300 7325 7350 7375 7400 7425 7450 7475 7500 7525 7550 7575 7600 7625 7650 7675 7700 7725 7750 7775 7800 7825 7850 7875 7900 7925 7950 7975 8000 \n",
            "8025 8050 8075 8100 8125 8150 8175 8200 8225 8250 8275 8300 8325 8350 8375 8400 8425 8450 8475 8500 8525 8550 8575 8600 8625 8650 8675 8700 8725 8750 8775 8800 8825 8850 8875 8900 8925 8950 8975 9000 \n",
            "9025 9050 9075 9100 9125 9150 9175 9200 9225 9250 9275 9300 9325 9350 9375 9400 9425 9450 9475 9500 9525 9550 9575 9600 9625 9650 9675 9700 9725 9750 9775 9800 9825 9850 9875 9900 9925 9950 9975 10000 \n",
            "10025 10050 10075 10100 10125 10150 10175 10200 10225 10250 10275 10300 10325 10350 10375 10400 10425 10450 10475 10500 10525 10550 10570 \n",
            "Predictions generated.\n",
            "Write: /content/drive/MyDrive/w266 NLP Final Project/Predictions/checkpoint/predictions.T5_base_pt_long.triviaqa.squad.csv\n",
            "/content/drive/MyDrive/w266 NLP Final Project/Data/triviaqa/valid_pairs.csv\n",
            "Generating predictions using triviaqa from 0 to 9835:\n",
            "25 50 75 100 125 150 175 200 225 250 275 300 325 350 375 400 425 450 475 500 525 550 575 600 625 650 675 700 725 750 775 800 825 850 875 900 925 950 975 1000 \n",
            "1025 1050 1075 1100 1125 1150 1175 1200 1225 1250 1275 1300 1325 1350 1375 1400 1425 1450 1475 1500 1525 1550 1575 1600 1625 1650 1675 1700 1725 1750 1775 1800 1825 1850 1875 1900 1925 1950 1975 2000 \n",
            "2025 2050 2075 2100 2125 2150 2175 2200 2225 2250 2275 2300 2325 2350 2375 2400 2425 2450 2475 2500 2525 2550 2575 2600 2625 2650 2675 2700 2725 2750 2775 2800 2825 2850 2875 2900 2925 2950 2975 3000 \n",
            "3025 3050 3075 3100 3125 3150 3175 3200 3225 3250 3275 3300 3325 3350 3375 3400 3425 3450 3475 3500 3525 3550 3575 3600 3625 3650 3675 3700 3725 3750 3775 3800 3825 3850 3875 3900 3925 3950 3975 4000 \n",
            "4025 4050 4075 4100 4125 4150 4175 4200 4225 4250 4275 4300 4325 4350 4375 4400 4425 4450 4475 4500 4525 4550 4575 4600 4625 4650 4675 4700 4725 4750 4775 4800 4825 4850 4875 4900 4925 4950 4975 5000 \n",
            "5025 5050 5075 5100 5125 5150 5175 5200 5225 5250 5275 5300 5325 5350 5375 5400 5425 5450 5475 5500 5525 5550 5575 5600 5625 5650 5675 5700 5725 5750 5775 5800 5825 5850 5875 5900 5925 5950 5975 6000 \n",
            "6025 6050 6075 6100 6125 6150 6175 6200 6225 6250 6275 6300 6325 6350 6375 6400 6425 6450 6475 6500 6525 6550 6575 6600 6625 6650 6675 6700 6725 6750 6775 6800 6825 6850 6875 6900 6925 6950 6975 7000 \n",
            "7025 7050 7075 7100 7125 7150 7175 7200 7225 7250 7275 7300 7325 7350 7375 7400 7425 7450 7475 7500 7525 7550 7575 7600 7625 7650 7675 7700 7725 7750 7775 7800 7825 7850 7875 7900 7925 7950 7975 8000 \n",
            "8025 8050 8075 8100 8125 8150 8175 8200 8225 8250 8275 8300 8325 8350 8375 8400 8425 8450 8475 8500 8525 8550 8575 8600 8625 8650 8675 8700 8725 8750 8775 8800 8825 8850 8875 8900 8925 8950 8975 9000 \n",
            "9025 9050 9075 9100 9125 9150 9175 9200 9225 9250 9275 9300 9325 9350 9375 9400 9425 9450 9475 9500 9525 9550 9575 9600 9625 9650 9675 9700 9725 9750 9775 9800 9825 9835 \n",
            "Predictions generated.\n",
            "Write: /content/drive/MyDrive/w266 NLP Final Project/Predictions/checkpoint/predictions.T5_base_pt_long.triviaqa.triviaqa.csv\n"
          ]
        }
      ],
      "source": [
        "for dataset_name in validation_dataset_names:\n",
        "  if dataset_name == \"squad\":\n",
        "    validation_data_file = f\"{dataset_root}squad.hf/valid_pairs.csv\"\n",
        "  else:  \n",
        "    validation_data_file = f\"{dataset_root}{dataset_name}/valid_pairs.csv\"\n",
        "  print(validation_data_file)\n",
        "  validation_df = pd.read_csv(validation_data_file)\n",
        "  prediction_file = f\"{prediction_folder}predictions.{model_name}.{dataset_name}.csv\" \n",
        "  \n",
        "  start_sample = None\n",
        "  end_sample = None\n",
        "\n",
        "  predictions = []\n",
        "  \n",
        "  if start_sample is None: start_sample = 0\n",
        "  if end_sample is None: end_sample = validation_df.shape[0]\n",
        "  \n",
        "  print(f\"Generating predictions using {dataset_name} from {start_sample} to {end_sample}:\")\n",
        "  for start in range (start_sample, end_sample, batch_size):\n",
        "    to = min([end_sample, start + batch_size])\n",
        "    inputs = T5_tokenizer(validation_df['orig'][start:to].to_list(), return_tensors='pt', max_length=max_input_length, truncation=True, padding=True)\n",
        "    output_ids = T5_model.generate(inputs['input_ids'].cuda(),\n",
        "                                   min_length=min_target_length,\n",
        "                                   max_length=max_target_length,\n",
        "                                   num_beams=num_beams, \n",
        "                                   no_repeat_ngram_size=no_repeat_ngram_size, \n",
        "                                   early_stopping=early_stopping)  \n",
        "    prediction_batch = T5_tokenizer.batch_decode(output_ids, skip_special_tokens=True)   \n",
        "    predictions.extend(prediction_batch)\n",
        "    print (f\"{to} \", end=\"\")\n",
        "    if to%1000 == 0: print()\n",
        "  print(\"\\nPredictions generated.\")\n",
        "\n",
        "  df=pd.DataFrame()\n",
        "  df['context'] = [str.split('context: ')[1] for str in validation_df['orig'][start_sample:end_sample]]\n",
        "  df['answer'] =  [str.split('context: ')[0][26: ] for str in validation_df['orig'][start_sample:end_sample]]\n",
        "  df['target'] = validation_df['target']\n",
        "  df['prediction'] = predictions\n",
        "\n",
        "  if save_predictions:\n",
        "    df.to_csv(prediction_file, mode=save_mode)\n",
        "    print(f\"Write: {prediction_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python [conda env:gpu]",
      "language": "python",
      "name": "conda-env-gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanlucjackson/w266_final_project/blob/main/code/inference/awesome_T5_pt_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Predictions From An Awesome Validation Dataset\n",
        "\n",
        "This notebook assumes a T5 PyTorch model.\n",
        "\n",
        "Setting the constants in the next call should be all that is necessary to run the validation set."
      ],
      "metadata": {
        "id": "Hh-4vVXTMhpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3jvE9TJRd4cG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set these constants for each model and validation dataset combination\n",
        "\n",
        "model_name = \"T5_base_pt_long.quac\"\n",
        "validation_dataset_name = \"triviaqa\"\n",
        "\n",
        "save_predictions = True\n",
        "save_mode = 'w' # w for write, a for append\n",
        "\n",
        "max_length = 1024 # 1024 for long model and 512 otherwise\n",
        "batch_size = 50 # 150 is the norm, but dial back when needed\n",
        "\n",
        "start_sample = 0\n",
        "end_sample = 5000"
      ],
      "metadata": {
        "id": "rlCLzceMMahp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Predictions"
      ],
      "metadata": {
        "id": "fJ8lW8X8NJ9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c3906UT0dyke",
        "outputId": "eeb55347-6ec5-43ce-f837-dc6c742ce0f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 35.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 80.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 92.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vBX23WXdd0v-",
        "outputId": "d15817ab-8c6b-435e-d340-82cf7155ff55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 23.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 184 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 215 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 225 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 235 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 245 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 256 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 276 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 286 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 296 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 307 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 327 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 337 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 348 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 358 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 368 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 378 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 389 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 399 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 409 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 419 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 430 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 440 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 450 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 460 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 471 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 481 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 491 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 501 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 512 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 522 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 532 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 542 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 552 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 563 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 573 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 583 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 593 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 604 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 614 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 624 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 634 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 645 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 655 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 665 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 675 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 686 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 696 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 706 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 716 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 727 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 737 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 747 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 757 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 768 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 778 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 788 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 798 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 808 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 819 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 829 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 839 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 849 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 860 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 870 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 880 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 890 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 901 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 911 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 921 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 931 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 942 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 952 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 962 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 972 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 983 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 993 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.0 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.0 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 23.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17N1XaF7d6dW",
        "outputId": "8ccbcc4f-1a83-4006-9711-46edc4ba5276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iMHoUiDnd9He"
      },
      "outputs": [],
      "source": [
        "# Some important file locations and constants\n",
        "\n",
        "project_root = \"/content/drive/MyDrive/w266 NLP Final Project/\"\n",
        "dataset_root = project_root + \"Data/\"\n",
        "model_root = project_root + \"Models/\"\n",
        "prediction_folder = project_root + \"Predictions/\"\n",
        "\n",
        "tokenizer = \"google/t5-v1_1-base\"\n",
        "\n",
        "model_folder = model_root + model_name\n",
        "\n",
        "validation_data_file = f\"{dataset_root}squad.hf/valid_pairs.csv\"\n",
        "if validation_dataset_name != \"squad\":\n",
        "  validation_data_file = f\"{dataset_root}{validation_dataset_name}/valid_pairs.csv\"\n",
        "\n",
        "prediction_file = f\"{prediction_folder}predictions.{model_name}.{validation_dataset_name}.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1520
        },
        "id": "aq5h729KfB5F",
        "outputId": "3c5d2662-57b7-4eac-c4bc-c143488c8f5f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                orig  \\\n",
              "0  generate question: answer: one context: Goliat...   \n",
              "1  generate question: answer: Apaches context: Ge...   \n",
              "\n",
              "                                              target  \n",
              "0  When David killed Goliath, how many of his fiv...  \n",
              "1  Of which tribe of Red Indians was Geronimo a c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81a9404c-1fed-46ae-85ed-de38f19da410\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>generate question: answer: one context: Goliat...</td>\n",
              "      <td>When David killed Goliath, how many of his fiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>generate question: answer: Apaches context: Ge...</td>\n",
              "      <td>Of which tribe of Red Indians was Geronimo a c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81a9404c-1fed-46ae-85ed-de38f19da410')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81a9404c-1fed-46ae-85ed-de38f19da410 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81a9404c-1fed-46ae-85ed-de38f19da410');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.module+javascript": "\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a8bd4d5e58f96183/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 0,\n            'f': \"0\",\n        },\n\"generate question: answer: one context: Goliath ( ; ; Arabic : \\u062c\\u0627\\u0644\\u0648\\u062a , \\u01e6\\u0101l\\u016bt ( Qur'anic term ) , \\u062c\\u0644\\u064a\\u0627\\u062a \\u01e6uly\\u0101t ( Christian term ) ) of Gath ( one of five city states of the Philistines ) was a giant Philistine warrior defeated by the young David , the future king of Israel . The story is told in the Bible 's Books of Samuel ( 1 Samuel 17 ) . \\n \\n The original purpose of the story was to show David 's identity as the true king of Israel . Post-Classical Jewish traditions stressed Goliath 's status as the representative of paganism , in contrast to David , the champion of the God of Israel . Christian tradition gave him a distinctively Christian perspective , seeing in David 's battle with Goliath the victory of God 's king over the enemies of God 's helpless people as a prefiguring of Jesus ' victory over sin on the cross and the Church 's victory over Satan . \\n \\n The phrase `` David and Goliath '' has taken on a more secular meaning , denoting an underdog situation , a contest where a smaller , weaker opponent faces a much bigger , stronger adversary . \\n \\n Biblical account \\n \\n The Goliath narrative in 1 Samuel 17 \\n \\n The account of the battle between David and Goliath is told in 1 Samuel , chapter 17 . Saul and the Israelites are facing the Philistines near the Valley of Elah . Twice a day for 40 days , Goliath , the champion of the Philistines , comes out between the lines and challenges the Israelites to send out a champion of their own to decide the outcome in single combat , but Saul and all the Israelites are afraid . David , bringing food for his elder brothers , hears that Goliath had defied the armies of God and of the reward from Saul to the one that defeats him , and accepts the challenge . Saul reluctantly agrees and offers his armor , which David declines , taking only his staff , sling ( q\\u0101la \\u2018 ) and five stones from a brook . \\n \\n David and Goliath confront each other , Goliath with his armor and javelin , David with his staff and sling . `` The Philistine cursed David by his gods '' , but David replies : `` This day the will deliver you into my hand , and I will strike you down ; and I will give the dead bodies of the host of the Philistines this day to the birds of the air and to the wild beasts of the earth ; that all the earth may know that there is a God in Israel , and that all this assembly may know that God saves not with sword and spear ; for the battle is God \\u2019 s , and he will give you into our hand . '' \\n \\n David hurls a stone from his sling with all his might and hits Goliath in the center of his forehead , Goliath falls on his face to the ground , and David cuts off his head . The Philistines flee and are pursued by the Israelites `` as far as Gath and the gates of Ekron '' . David puts the armor of Goliath in his own tent and takes the head to Jerusalem , and Saul sends Abner to bring the boy to him . The king asks whose son he is , and David answers , `` I am the son of your servant Jesse the Bethlehemite . '' \\n \\n Composition of the Book of Samuel and the Goliath narrative \\n \\n The Book of Samuel , together with the books of Joshua , Judges and Kings , make up a unified history of Israel stretching from the entry into Canaan to the early Babylonian exile of the 6th century BCE , which biblical scholars call the Deuteronomistic history . The first edition of the history was probably written at the court of Judah 's King Josiah ( late 7th century ) and a revised second edition during the exile ( 6th century ) , with further revisions in the post-exilic period . The Goliath story contains the traces of this in its many contradictions and illogicalities - to take a few examples , Saul finds it necessary to send for David when as the king 's shield-bearer he should already be beside his royal master , and he has to ask who David is , which sits strangely with David 's status at his court . These signs indicate that the Goliath story is made up of base-narrative with numerous additions made probably after the exile . \\n \\n Original\",\n\"When David killed Goliath, how many of his five stones did he use?\"],\n [{\n            'v': 1,\n            'f': \"1\",\n        },\n\"generate question: answer: Apaches context: Geronimo ( `` the one who yawns '' ; June 16 , 1829 \\u2013 February 17 , 1909 ) was a prominent leader from the Bedonkohe band of the Chiricahua Apache tribe . From 1850 to 1886 Geronimo joined with members of three other Chiricahua Apache bands\\u2014the Chihenne , the Chokonen and the Nednhi\\u2014to carry out numerous raids as well as resistance to US and Mexican military campaigns in the northern Mexico states of Chihuahua and Sonora , and in the southwestern American territories of New Mexico and Arizona . Geronimo 's raids and related combat actions were a part of the prolonged period of the Apache-American conflict , that started with American settlement in Apache lands following the end of the war with Mexico in 1848 . The Apache-American conflict was itself a direct outgrowth of the much older Apache-Mexican conflict which had been ongoing in the same general area since the beginning of Mexican/Spanish settlement in the 1600s . \\n \\n During the centuries of Apache-Mexican and Apache-American conflict , raiding had become embedded in the Apache way of life , used not only for strategic purposes but also as an economic enterprise , and often there was overlap between raids for economic need and warfare . Raids ranged from stealing livestock and other plunder , to the capture and/or violent killing of victims , sometimes by torture . Mexicans and Americans responded with retaliation attacks against the Apache which were no less violent , and were often indiscriminate . The raiding and retaliation fed the fires of a virulent revenge warfare that reverberated back and forth between Apaches and Mexicans and later , Apaches and Americans . This was a deadly , brutal and barbaric business for all sides . From 1850 to 1886 Geronimo as well as other Apache leaders conducted raids and carried on revenge warfare , but Geronimo accumulated a record during this time that matched any of his contemporaries , and his fighting ability extending over 30 years form a major characteristic of his persona . \\n \\n Geronimo was not counted a chief among the Apache . At any one time , only about 30 to 50 Apaches would be numbered among his personal following . However , since he was a superb leader in raiding and revenge warfare he frequently led numbers larger than his own following . Among Geronimo 's own Chiricahua tribe many had mixed feelings about him\\u2014while respected as a skilled and effective leader of raids or warfare , he emerges as not very likable , and he was not widely popular among the other Apache . Nevertheless , Apache people stood in awe of Geronimo 's `` powers '' which he demonstrated to them on a series of occasions . These powers indicated to other Apaches that Geronimo had super-natural gifts that he could use for good or ill . In eye-witness accounts by other Apaches , Geronimo was able to become aware of distant events as they happened , and he was able to anticipate events that were in the future . He also demonstrated powers to heal other Apaches . \\n \\n Early in his life , Geronimo became invested in the continuing and relentless cycle of revenge warfare between Apache and Mexican . On March 5 , 1851 , when Geronimo was in his 20 's , a force of Mexican militia from Sonora under Colonel Jose Maria Carrasco attacked and surprised an Apache camp outside of Janos , Chihuahua , slaughtering the inhabitants which included Geronimo 's family . Col. Carrasco claimed he had followed the Apaches to Janos , Chihuahua after they had conducted a raid in Sonora , taken livestock and other plunder and badly defeated Mexican militia . Geronimo was absent at the time of the attack on the Apache camp , but when he returned he found that his mother , wife , and his three children were among the dead . In retaliation , Geronimo joined in an extended series of revenge attacks against the Mexicans . This event left Geronimo with a bitter and very personal hatred for Mexicans , and he often killed them indiscriminately and with a special vehemence . Throughout Geronimo 's adult life his antipathy , suspicion and dislike for Mexicans was demonstrably greater than for Americans . \\n \\n During Geronimo 's final period of conflict from 1876 to 1886 he `` surrendered '' three times and accepted life on the Apache reservations in Arizona . Reservation life was confining to the free-moving Apache people , and they resented restrictions on their customary way of life . While Apaches were shielded from the violence of warfare on the reservation , disability and death from diseases like malaria was much more prevalent .\",\n\"Of which tribe of Red Indians was Geronimo a chief\"]],\n        columns: [[\"number\", \"index\"], [\"string\", \"orig\"], [\"string\", \"target\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "validation_df = pd.read_csv(validation_data_file)\n",
        "validation_df[['orig', 'target']][:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_df.shape[0]"
      ],
      "metadata": {
        "id": "za89_yTEQE3j",
        "outputId": "3346798b-71a3-4942-f48d-b61877288399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9835"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VHLLVOB4fG5W"
      },
      "outputs": [],
      "source": [
        "# Download tokenizer and model, associate the model with the GPU\n",
        "\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(tokenizer)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(model_folder)\n",
        "t5_model.to(torch.device('cuda:0'))\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "if end_sample is None:\n",
        "  end_sample = validation_df.shape[0]\n",
        "\n",
        "print(\"Generating predictions from {start_sample} to {end_sample}:\")\n",
        "for start in range (start_sample, end_sample, batch_size):\n",
        "  to = min([count, start + batch_size])\n",
        "  inputs = t5_tokenizer(validation_df['orig'][start:to].to_list(), return_tensors='pt', max_length=max_length, truncation=True, padding=True)\n",
        "  output_ids = t5_model.generate(inputs['input_ids'].cuda(), max_length=max_length)\n",
        "  prediction_batch = t5_tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
        "  predictions.extend(prediction_batch)\n",
        "  print (f\"{to} \", end=\"\")\n",
        "  if to%1000 == 0: print()\n",
        "print(\"Predictions generated.\")"
      ],
      "metadata": {
        "id": "wnD8aDG2_GpV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "outputId": "ec365326-c1eb-4185-a1b5-c0e490ca8f3c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions:\n",
            "50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 \n",
            "1050 1100 1150 1200 1250 1300 1350 1400 1450 1500 1550 1600 1650 1700 1750 1800 1850 1900 1950 2000 \n",
            "2050 2100 2150 2200 2250 2300 2350 2400 2450 2500 2550 2600 2650 2700 2750 2800 2850 2900 2950 3000 \n",
            "3050 3100 3150 3200 3250 3300 3350 3400 3450 3500 3550 3600 3650 3700 3750 3800 3850 3900 3950 4000 \n",
            "4050 4100 4150 4200 4250 4300 4350 4400 4450 4500 4550 4600 4650 4700 4750 4800 4850 4900 4950 5000 \n",
            "5050 5100 5150 5200 5250 5300 5350 5400 5450 5500 5550 5600 5650 5700 5750 5800 5850 5900 5950 6000 \n",
            "6050 6100 6150 6200 "
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-53bada81395c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mprediction_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt5_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, penalty_alpha, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1497\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m             )\n\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   2235\u001b[0m                 \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2237\u001b[0;31m                 \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2238\u001b[0m             )\n\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1660\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1661\u001b[0m         )\n\u001b[1;32m   1662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1049\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 )\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mquery_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             )\n\u001b[1;32m    710\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mquery_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         )\n\u001b[1;32m    624\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# compute scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         scores = torch.matmul(\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         )  # equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 150.00 MiB (GPU 0; 14.76 GiB total capacity; 11.56 GiB already allocated; 21.75 MiB free; 13.74 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBYDU6c8jMoU"
      },
      "outputs": [],
      "source": [
        "df=pd.DataFrame()\n",
        "df['context'] = [str.split('context: ')[1] for str in validation_df['orig']]\n",
        "df['answer'] =  [str.split('context: ')[0][26: ] for str in validation_df['orig']]\n",
        "df['target'] = validation_df['target']\n",
        "df['prediction'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hILCbzSCzLBY"
      },
      "outputs": [],
      "source": [
        "df[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKzojpnFqbLN"
      },
      "outputs": [],
      "source": [
        "if save_predictions:\n",
        "  df.to_csv(prediction_file, mode=save_mode)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "fJ8lW8X8NJ9o"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanlucjackson/w266_final_project/blob/main/code/model_training/awesome_T5_pt_train_seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hId0nV1UMJct",
        "outputId": "4c722913-a666-4d2c-ef8c-92ab47ee688f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TTtEecIFzQ_j"
      },
      "outputs": [],
      "source": [
        "model_name = \"/content/drive/MyDrive/w266 NLP Final Project/Models/T5_base_pt_long.sn/\"\n",
        "tokenizer_name = \"google/t5-v1_1-base\"\n",
        "dataset_name = \"quac\"\n",
        "max_length=1024\n",
        "batch_size=4\n",
        "\n",
        "# Modify this filepath to where you want to save the model after fine-tuning\n",
        "dir_path = \"/content/drive/MyDrive/w266 NLP Final Project/Models/T5_base_pt_long.snq/\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJmgxZ_-LcoX"
      },
      "source": [
        "## Question Generation using T5 in Colab without running out of RAM\n",
        "\n",
        "This notebook is based on Natalie Ahn's notebook showing how to fine tune T5 in Colab without running out of RAM.  It is limited to PyTorch and has been modified to increase the speed of the dataset generators by dramatically reducing the amount of disk I/O."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oMWJ_MH1Lgsg"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gao8Q8P-edDd"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4fKpWjWlMJZo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YoBb_fmzlitt"
      },
      "outputs": [],
      "source": [
        "dataset_root = \"/content/drive/MyDrive/w266 NLP Final Project/Data/\"\n",
        "\n",
        "dataset_folder = dataset_root+dataset_name\n",
        "training_file = dataset_folder + '/train_pairs.csv'\n",
        "validation_file = dataset_folder + '/valid_pairs.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BVKtkZfxIj9N"
      },
      "outputs": [],
      "source": [
        "training_df = pd.read_csv(training_file)\n",
        "validation_df = pd.read_csv(validation_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "l_RC2nkunB4M",
        "outputId": "c36d2aea-c54b-4804-b83a-53c90584da22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                orig  \\\n",
              "0  generate question: answer: Jonny Lang's Still ...   \n",
              "1  generate question: answer: The circuits overca...   \n",
              "2  generate question: answer: In the generic plan...   \n",
              "\n",
              "                                              target  \n",
              "0     What are some of the performances he has done?  \n",
              "1                  How far could the images be sent?  \n",
              "2  Are there any other interesting aspects about ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8f4e54d-8cde-421f-b955-84e00237a5ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>generate question: answer: Jonny Lang's Still ...</td>\n",
              "      <td>What are some of the performances he has done?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>generate question: answer: The circuits overca...</td>\n",
              "      <td>How far could the images be sent?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>generate question: answer: In the generic plan...</td>\n",
              "      <td>Are there any other interesting aspects about ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8f4e54d-8cde-421f-b955-84e00237a5ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8f4e54d-8cde-421f-b955-84e00237a5ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8f4e54d-8cde-421f-b955-84e00237a5ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "training_df[:3][['orig', 'target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "veIAXuYTnD3Z",
        "outputId": "744f4a9a-50a2-4430-db58-739c8c434918"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                orig  \\\n",
              "0  generate question: answer: Greaves later admit...   \n",
              "1  generate question: answer: Kapoor is of Hindu ...   \n",
              "2  generate question: answer: On September 20, 20...   \n",
              "\n",
              "                                            target  \n",
              "0     Did Jimmy learn a lesson at West Ham United?  \n",
              "1  What do you find interesting about the article?  \n",
              "2               What number album was You Fail Me?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8f715b8-aa31-4a9b-abd4-28e32fd76db4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>orig</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>generate question: answer: Greaves later admit...</td>\n",
              "      <td>Did Jimmy learn a lesson at West Ham United?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>generate question: answer: Kapoor is of Hindu ...</td>\n",
              "      <td>What do you find interesting about the article?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>generate question: answer: On September 20, 20...</td>\n",
              "      <td>What number album was You Fail Me?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8f715b8-aa31-4a9b-abd4-28e32fd76db4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8f715b8-aa31-4a9b-abd4-28e32fd76db4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8f715b8-aa31-4a9b-abd4-28e32fd76db4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "validation_df[:3][['orig', 'target']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0VEFHBNBHF-C"
      },
      "outputs": [],
      "source": [
        "def preprocess_data_pt(text_pair, tokenizer, max_length=max_length):\n",
        "    orig_text, target_text = text_pair\n",
        "    orig_encoded = tokenizer.batch_encode_plus(\n",
        "        [orig_text],\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    orig_input_ids = orig_encoded['input_ids'][0]\n",
        "    orig_attention_mask = orig_encoded['attention_mask'][0]\n",
        "    \n",
        "    target_encoded = tokenizer.batch_encode_plus(\n",
        "        [target_text],\n",
        "        max_length=max_length,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    label_ids = target_encoded['input_ids'][0]\n",
        "    \n",
        "    return {'input_ids': orig_input_ids,\n",
        "            'attention_mask': orig_attention_mask,\n",
        "            'labels': label_ids}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aTahX_whHGAq"
      },
      "outputs": [],
      "source": [
        "class TranslationDataGeneratorPT(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 data_filename,\n",
        "                 max_length=max_length,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.data = pd.read_csv(data_filename)\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        row_to_load = self.row_order[idx]\n",
        "        df = self.data[self.row_order[idx] - 1: self.row_order[idx]]\n",
        "        \n",
        "        text_pairs = df[['orig', 'target']].values.astype(str)[0]\n",
        "        \n",
        "        batch_data = preprocess_data_pt(\n",
        "            text_pairs,\n",
        "            self.tokenizer,\n",
        "            self.max_length\n",
        "        )\n",
        "\n",
        "        return batch_data\n",
        "    \n",
        "    def __call__(self):\n",
        "        for i in range(self.__len__()):\n",
        "            yield self.__getitem__(i)\n",
        "            \n",
        "            if i == self.__len__()-1:\n",
        "                self.on_epoch_end()\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BfK_F7p5P5ir"
      },
      "outputs": [],
      "source": [
        "# Download tokenizer and model\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FuSczzguHGDO"
      },
      "outputs": [],
      "source": [
        "# Create the data generators for train and validation data, pytorch version\n",
        "\n",
        "train_data_generator = TranslationDataGeneratorPT(\n",
        "    tokenizer=tokenizer,\n",
        "    n_examples=training_df.shape[0],\n",
        "    data_filename=training_file,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "valid_data_generator = TranslationDataGeneratorPT(\n",
        "    tokenizer=tokenizer,\n",
        "    n_examples=validation_df.shape[0],\n",
        "    data_filename=validation_file,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "QHGnHso9bSbI"
      },
      "outputs": [],
      "source": [
        "file_path = dir_path + 'checkpoints'\n",
        "\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    file_path,\n",
        "    save_steps=2000,\n",
        "    save_total_limit=5,\n",
        "    evaluation_strategy='epoch',\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "zx4fOPVJLoLn"
      },
      "outputs": [],
      "source": [
        "# Define the trainer, passing in the model, training args, and data generators\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_data_generator,\n",
        "    eval_dataset=valid_data_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "QF-x_gTibIN2",
        "outputId": "72384c5e-68ff-47d5-8cd6-fd27b3394119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 69109\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 17278\n",
            "  Number of trainable parameters = 247577856\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='811' max='17278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  811/17278 10:11 < 3:27:17, 1.32 it/s, Epoch 0.05/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Call train\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pX3JwHy_ZuTk"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(dir_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-FZo2D61dsB"
      },
      "source": [
        "### Post Training Review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oCdO-DGcKrz"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4tUpum7bwEE"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"/content/drive/MyDrive/w266 NLP Final Project/Models/T5_base_pt_long.snq/checkpoints\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwGhRWsnZj_"
      },
      "source": [
        "### Does it seem to have worked?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MjDTPy1jD8i"
      },
      "outputs": [],
      "source": [
        "sample_df = validation_df[0:20].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMRlS4LqbIaf"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for input_text in sample_df['orig']:\n",
        "  inputs = tokenizer(input_text, return_tensors='pt', max_length=max_length, truncation=True)\n",
        "  output_ids = model.generate(inputs['input_ids'].cuda(), max_length=50)\n",
        "  prediction = \"\".join([tokenizer.decode(out_ids, skip_special_tokens=True, \n",
        "                                            clean_up_tokenization_spaces=False) for out_ids in output_ids])\n",
        "  predictions.append(prediction)\n",
        "\n",
        "sample_df['prediction'] = predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v95uMvYGmLU_"
      },
      "outputs": [],
      "source": [
        "sample_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NffN-QTEQV17"
      },
      "source": [
        "You can load the model you trained using the .from_pretrained function you use for pretrained models. If you look in your drive folder, at the filepath you used in the trainer arguments, you'll see a checkpoint folder. Use the full path to that checkpoint folder as the argument to .from_pretrained, to load the model you saved again later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AKDOxmxzatj"
      },
      "outputs": [],
      "source": [
        "bart_model_saved = T5ForConditionalGeneration.from_pretrained(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2Ahbd8CQ7U_"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda:0')\n",
        "bart_model_saved.to(device)\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU2U74l_RyQX"
      },
      "outputs": [],
      "source": [
        "dir_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xR1_HTh3zavY"
      },
      "outputs": [],
      "source": [
        "# Still works?\n",
        "predictions = []\n",
        "for input_text in sample_df['orig']:\n",
        "  inputs = tokenizer(input_text, return_tensors='pt', max_length=max_length, truncation=True)\n",
        "  output_ids = bart_model_saved.generate(inputs['input_ids'].cuda(), max_length=max_length)\n",
        "  prediction = \"\".join([tokenizer.decode(out_ids, skip_special_tokens=True, \n",
        "                                    clean_up_tokenization_spaces=False) for out_ids in output_ids])\n",
        "  predictions.append(prediction)\n",
        "\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
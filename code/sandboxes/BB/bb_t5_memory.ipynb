{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN9fgs1dfvdmvZ67xF3A1rg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanlucjackson/w266_final_project/blob/main/code/BB/bb_t5_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S71cSTrx7QAo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "# Make longer output readable without scrolling\n",
        "from pprint import pprint\n",
        "\n",
        "# Stop warning messages from showing\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPEFNeUY7Q1j",
        "outputId": "e5705b70-c592-4c29-d3ae-e7c240c7cb47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO-94Kyg7c1-",
        "outputId": "27adb9ad-00f5-429d-c12e-b276f0eeb68d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 37.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 43.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ApLdGCt7dB-",
        "outputId": "312e422e-dda3-4b97-a939-69339ec1eb28"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 441 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 53.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 50.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 43.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 45.7 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate\n",
        "import evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qx6CwXY7dEj",
        "outputId": "55001ee6-6abb-4527-ce78-eff7df8ea2f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 51 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 71 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 831 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw52OoZj224h",
        "outputId": "a8154930-992e-48b8-bcd3-a4eea9133b3d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset_builder, get_dataset_config_names, load_dataset, load_from_disk\n"
      ],
      "metadata": {
        "id": "jKnm9ycN17FJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_dataset (dataset, config=None):\n",
        "    builder = load_dataset_builder(dataset, config)\n",
        "    print(f\"Description:\\n {builder.info.description}\")\n",
        "    print(f\"Features:\")\n",
        "    pprint(builder.info.features)\n",
        "    return"
      ],
      "metadata": {
        "id": "AWBlx1YD2YJ8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load SQuAD dataset from Gdrive"
      ],
      "metadata": {
        "id": "3WNWamSV2-JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_squad = load_from_disk(\"/content/drive/MyDrive/w266 NLP Final Project/Data/squad.hf\")"
      ],
      "metadata": {
        "id": "5886MGVa17Ma"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mseSStDq17Ox",
        "outputId": "e3f5edc9-e140-495a-b9f0-a9670a5f848f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at first example\n",
        "pprint(data_squad['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHhZXyX23JKc",
        "outputId": "a5bbb944-33c7-4983-dd20-4693c7bc69d8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
            " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
            "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
            "            'Immediately in front of the Main Building and facing it, is a '\n",
            "            'copper statue of Christ with arms upraised with the legend '\n",
            "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
            "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
            "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
            "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
            "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
            "            'main drive (and in a direct line that connects through 3 statues '\n",
            "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
            " 'id': '5733be284776f41900661182',\n",
            " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
            "             'France?',\n",
            " 'title': 'University_of_Notre_Dame'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T5v1.1 Model\n",
        "\n",
        "Sources: https://huggingface.co/docs/transformers/model_doc/t5\n",
        "https://huggingface.co/docs/transformers/model_doc/t5v1.1"
      ],
      "metadata": {
        "id": "ctGQSdG5BdKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "t5_model = TFT5ForConditionalGeneration.from_pretrained(\"google/t5-v1_1-base\")\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9k8gX-V7Q4E",
        "outputId": "19f82d73-4963-48ea-9cf1-e14330cc3c8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/t5-v1_1-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2snEtEk7Q6v",
        "outputId": "af12fab1-71bb-4666-9fec-9bf16aaa4580"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tft5_for_conditional_generation_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " shared (TFSharedEmbeddings)  multiple                 24674304  \n",
            "                                                                 \n",
            " encoder (TFT5MainLayer)     multiple                  84954240  \n",
            "                                                                 \n",
            " decoder (TFT5MainLayer)     multiple                  113275008 \n",
            "                                                                 \n",
            " lm_head (Dense)             multiple                  24674304  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 247,577,856\n",
            "Trainable params: 247,577,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train model with limited RAM"
      ],
      "metadata": {
        "id": "dfGm6KpYfZ22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep data"
      ],
      "metadata": {
        "id": "2GFvdCWDgQrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe for train data \n",
        "# shuffle so random\n",
        "data_shuffle=data_squad['train'].shuffle(seed=1962)\n",
        "df=pd.DataFrame()\n",
        "df['answer'] = [answer['text'][0] for answer in data_shuffle['answers']]\n",
        "df['context'] = data_shuffle['context']\n",
        "df['question'] = data_shuffle['question']\n",
        "\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "veqZzKbBiKWu",
        "outputId": "9c50b1ef-6b0f-466d-b684-4549a6c79758"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /content/drive/MyDrive/w266 NLP Final Project/Data/squad.hf/train/cache-8ab9b6302b91254a.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             answer  \\\n",
              "0                 biotech companies   \n",
              "1               Tytus Woyciechowski   \n",
              "2  the Endangered Species Committee   \n",
              "3                             China   \n",
              "4                          45 years   \n",
              "\n",
              "                                             context  \\\n",
              "0  Prior to moving its headquarters to Chicago, a...   \n",
              "1  Four boarders at his parents' apartments becam...   \n",
              "2  The question to be answered is whether a liste...   \n",
              "3  In Asian countries such as China, Korea, and J...   \n",
              "4  Saint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/;...   \n",
              "\n",
              "                                            question  \n",
              "0  What type of businesses did Nickles want to at...  \n",
              "1  To whom did Chopin reveal in letters which par...  \n",
              "2  If a species may be harmed, who holds final sa...  \n",
              "3  What country has the dog as part of its 12 ani...  \n",
              "4                  How long did his episcopate last?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2b30430-1572-4830-a564-7497e07c86d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>biotech companies</td>\n",
              "      <td>Prior to moving its headquarters to Chicago, a...</td>\n",
              "      <td>What type of businesses did Nickles want to at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tytus Woyciechowski</td>\n",
              "      <td>Four boarders at his parents' apartments becam...</td>\n",
              "      <td>To whom did Chopin reveal in letters which par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Endangered Species Committee</td>\n",
              "      <td>The question to be answered is whether a liste...</td>\n",
              "      <td>If a species may be harmed, who holds final sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China</td>\n",
              "      <td>In Asian countries such as China, Korea, and J...</td>\n",
              "      <td>What country has the dog as part of its 12 ani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45 years</td>\n",
              "      <td>Saint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/;...</td>\n",
              "      <td>How long did his episcopate last?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2b30430-1572-4830-a564-7497e07c86d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2b30430-1572-4830-a564-7497e07c86d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2b30430-1572-4830-a564-7497e07c86d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save train data to csv\n",
        "df.to_csv(\"/content/drive/MyDrive/w266 NLP Final Project/Data/data_squad_train.csv\", index=False)"
      ],
      "metadata": {
        "id": "JBSMZNTChPym"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in csv of train data\n",
        "train_filename = \"/content/drive/MyDrive/w266 NLP Final Project/Data/data_squad_train.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_filename)\n",
        "\n",
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAtbG4x_jgSo",
        "outputId": "d0deadc9-290e-41b0-8136-1519e1a01b63"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(87599, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess data"
      ],
      "metadata": {
        "id": "SGIBnLtakLH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_txt = [f\"gq answer: {answer} context: {context}\" for answer, context in zip (df.answer, df.context)]\n",
        "\n",
        "output_txt = df.question.to_list()\n",
        "\n",
        "input_txt[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "7GvTLXQakdOP",
        "outputId": "747bd329-2382-4cfe-ab7e-6b2842c225bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gq answer: Tytus Woyciechowski context: Four boarders at his parents\\' apartments became Chopin\\'s intimates: Tytus Woyciechowski, Jan Nepomucen Białobłocki, Jan Matuszyński and Julian Fontana; the latter two would become part of his Paris milieu. He was friendly with members of Warsaw\\'s young artistic and intellectual world, including Fontana, Józef Bohdan Zaleski and Stefan Witwicki. He was also attracted to the singing student Konstancja Gładkowska. In letters to Woyciechowski, he indicated which of his works, and even which of their passages, were influenced by his fascination with her; his letter of 15 May 1830 revealed that the slow movement (Larghetto) of his Piano Concerto No. 1 (in E minor) was secretly dedicated to her – \"It should be like dreaming in beautiful springtime – by moonlight.\" His final Conservatory report (July 1829) read: \"Chopin F., third-year student, exceptional talent, musical genius.\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Training\n",
        "\n",
        "# # Encode inputs\n",
        "# inputs = tokenizer(input_txt, max_length=1024, padding=True, truncation=True, return_tensors=\"tf\")\n",
        "# #.input_ids\n",
        "# # Identify input ids and attention mask\n",
        "# input_ids, attention_mask = inputs.input_ids, inputs.attention_mask\n",
        "\n",
        "# # Encode outputs/targets\n",
        "# labels = tokenizer(output_txt, max_length=1024, padding=True, truncation=True, return_tensors=\"tf\").input_ids\n",
        "\n",
        "# outputs = model(input_ids=input_ids, \n",
        "#                 attention_mask=attention_mask, \n",
        "#                 labels=labels)\n",
        "# loss = outputs.loss\n",
        "# logits = outputs.logits"
      ],
      "metadata": {
        "id": "V-xo7xLeGT8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function to preprocess data\n",
        "\n",
        "def preprocess_data(input_txt, output_txt, tokenizer, max_length=1024):\n",
        "    # Encode inputs\n",
        "    encoded = tokenizer(input_txt, \n",
        "                        max_length=max_length, \n",
        "                        padding=True, \n",
        "                        truncation=True, \n",
        "                        return_tensors=\"tf\"\n",
        "                        )\n",
        "\n",
        "    # Extract encoded features and labels, add to corresponding lists\n",
        "    input_ids = encoded.input_ids\n",
        "    attention_masks = encoded.attention_mask\n",
        "\n",
        "    # Encode outputs\n",
        "    labels = tokenizer(output_txt, \n",
        "                       max_length=max_length, \n",
        "                       padding=True, \n",
        "                       truncation=True, \n",
        "                       return_tensors=\"tf\").input_ids\n",
        "    \n",
        "    return [input_ids, attention_masks], labels"
      ],
      "metadata": {
        "id": "J9TKfkORkFBm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "9nGNapiqdko6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SNLIDataGeneratorFromFile(tf.keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 n_examples,\n",
        "                 data_filename,\n",
        "                 max_length=128,\n",
        "                 batch_size=32,\n",
        "                 shuffle=True):\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.n_examples = n_examples\n",
        "        self.data_filename = data_filename\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        # Initialize row order, call on_epoch_end to shuffle row indices\n",
        "        self.row_order = np.arange(1, self.n_examples+1)\n",
        "        self.on_epoch_end()\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.n_examples // self.batch_size\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        batch_start = idx * self.batch_size\n",
        "        batch_end = (idx + 1) * self.batch_size\n",
        "\n",
        "        # Indices to skip are the ones in the shuffled row_order before and\n",
        "        # after the chunk we'll use for this batch\n",
        "        batch_idx_skip = self.row_order[:batch_start] + self.row_order[batch_end:]\n",
        "        df = pd.read_csv(self.data_filename, skiprows=batch_idx_skip)\n",
        "        \n",
        "        input_txt = [f\"gq answer: {answer} context: {context}\" for answer, context in zip (df.answer, df.context)]\n",
        "        output_txt = df.question.to_list()\n",
        "\n",
        "        batch_data = preprocess_data(\n",
        "            input_txt,\n",
        "            output_txt,\n",
        "            self.tokenizer,\n",
        "            self.max_length\n",
        "        )\n",
        "\n",
        "        return batch_data\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.row_order = list(np.random.permutation(self.row_order))"
      ],
      "metadata": {
        "id": "5L3BtEVqbqEn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator = SNLIDataGeneratorFromFile(\n",
        "    tokenizer=t5_tokenizer,\n",
        "    n_examples=5000,\n",
        "    data_filename=\"/content/drive/MyDrive/w266 NLP Final Project/Data/data_squad_train.csv\"\n",
        ")"
      ],
      "metadata": {
        "id": "2xLszZcabqK9"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path in drive where we want to save checkpoints\n",
        "!ls \"/content/drive/MyDrive/w266 NLP Final Project/Checkpoints/\""
      ],
      "metadata": {
        "id": "FvMbqm9jbqQ9"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE checkpoint_dir TO THE PATH IN YOUR OWN DRIVE WHERE YOU WANT TO SAVE CHECKPOINTS\n",
        "\n",
        "checkpoint_dir = \"/content/drive/MyDrive/w266 NLP Final Project/Checkpoints/\"\n",
        "checkpoint_filepath = checkpoint_dir + 'weights.{epoch:02d}-{val_accuracy:.2f}.hdf5'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "aY0I4jJLbqTi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now train model\n",
        "t5_model.generate(train_data_generator,\n",
        "                  # num_beams=2,\n",
        "                  # no_repeat_ngram_size=1,\n",
        "                  max_length=40\n",
        "               )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "Fs2P4HOxbqYN",
        "outputId": "980bc537-43d7-4bf4-c472-8777495c603f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5851409248ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0;31m# num_beams=2,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0;31m# no_repeat_ngram_size=1,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mbegin_suppress_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbegin_suppress_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mforced_decoder_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforced_decoder_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             )\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, input_ids, max_length, max_new_tokens, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, num_return_sequences, attention_mask, decoder_start_token_id, use_cache, seed, output_scores, output_attentions, output_hidden_states, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, suppress_tokens, begin_suppress_tokens, forced_decoder_ids, **model_kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m                 \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: TypeError: Scalar tensor has no `len()`\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1106, in __len__\n    raise TypeError(\"Scalar tensor has no `len()`\")\n\nTypeError: Scalar tensor has no `len()`\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrI4MbMtpQ1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b6CnHftcpQ3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42s5xeiorv-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMV7n9Eow+9I3v9sUmQjFEu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeanlucjackson/w266_final_project/blob/main/code/BB/bb_exploring_t5v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S71cSTrx7QAo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "\n",
        "# Make longer output readable without scrolling\n",
        "from pprint import pprint\n",
        "\n",
        "# Stop warning messages from showing\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPEFNeUY7Q1j",
        "outputId": "6cb5ec78-0e91-403d-8c69-aa33b23d37e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO-94Kyg7c1-",
        "outputId": "85e19fb1-b3ee-4a97-b7e1-a50874572a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 163 kB 32.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 39.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ApLdGCt7dB-",
        "outputId": "9bc70ab2-41bb-4074-aa6a-319e72be2580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 441 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 55.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 46.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q evaluate\n",
        "import evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qx6CwXY7dEj",
        "outputId": "8b54e9b3-ac2d-4553-f091-da6e131c6aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▌                           | 10 kB 18.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 20 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 72 kB 953 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw52OoZj224h",
        "outputId": "541d74ce-ccf6-4185-af67-c625fc7a11c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import list_datasets, load_dataset_builder, get_dataset_config_names, load_dataset, load_from_disk\n"
      ],
      "metadata": {
        "id": "jKnm9ycN17FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_dataset (dataset, config=None):\n",
        "    builder = load_dataset_builder(dataset, config)\n",
        "    print(f\"Description:\\n {builder.info.description}\")\n",
        "    print(f\"Features:\")\n",
        "    pprint(builder.info.features)\n",
        "    return"
      ],
      "metadata": {
        "id": "AWBlx1YD2YJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load SQuAD dataset from Gdrive"
      ],
      "metadata": {
        "id": "3WNWamSV2-JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_squad = load_from_disk(\"/content/drive/MyDrive/w266 NLP Final Project/Data/squad.hf\")"
      ],
      "metadata": {
        "id": "5886MGVa17Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_squad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mseSStDq17Ox",
        "outputId": "56f14768-5fd7-4124-98df-54c23371d4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at first example\n",
        "pprint(data_squad['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHhZXyX23JKc",
        "outputId": "c65f34bd-877b-4a33-e7d7-9fe5d9e25f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'answers': {'answer_start': [515], 'text': ['Saint Bernadette Soubirous']},\n",
            " 'context': 'Architecturally, the school has a Catholic character. Atop the '\n",
            "            \"Main Building's gold dome is a golden statue of the Virgin Mary. \"\n",
            "            'Immediately in front of the Main Building and facing it, is a '\n",
            "            'copper statue of Christ with arms upraised with the legend '\n",
            "            '\"Venite Ad Me Omnes\". Next to the Main Building is the Basilica '\n",
            "            'of the Sacred Heart. Immediately behind the basilica is the '\n",
            "            'Grotto, a Marian place of prayer and reflection. It is a replica '\n",
            "            'of the grotto at Lourdes, France where the Virgin Mary reputedly '\n",
            "            'appeared to Saint Bernadette Soubirous in 1858. At the end of the '\n",
            "            'main drive (and in a direct line that connects through 3 statues '\n",
            "            'and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
            " 'id': '5733be284776f41900661182',\n",
            " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes '\n",
            "             'France?',\n",
            " 'title': 'University_of_Notre_Dame'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### T5v1.1 Model\n",
        "\n",
        "Sources: https://huggingface.co/docs/transformers/model_doc/t5\n",
        "https://huggingface.co/docs/transformers/model_doc/t5v1.1"
      ],
      "metadata": {
        "id": "ctGQSdG5BdKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(\"google/t5-v1_1-base\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/t5-v1_1-base\")\n",
        "\n",
        "\n",
        "# model = TFT5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9k8gX-V7Q4E",
        "outputId": "bff66fae-91eb-4c81-a278-8f6665e91492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/t5-v1_1-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2snEtEk7Q6v",
        "outputId": "4367f941-59fc-45ee-8546-01bb46cf88f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tft5_for_conditional_generation_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " shared (TFSharedEmbeddings)  multiple                 24674304  \n",
            "                                                                 \n",
            " encoder (TFT5MainLayer)     multiple                  84954240  \n",
            "                                                                 \n",
            " decoder (TFT5MainLayer)     multiple                  113275008 \n",
            "                                                                 \n",
            " lm_head (Dense)             multiple                  24674304  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 247,577,856\n",
            "Trainable params: 247,577,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Structure\n",
        "\n",
        "The input data should be a single list of dictionaries (or path to a JSON file containing the same). A dictionary represents a single context and its associated questions.\n",
        "\n",
        "Each such dictionary contains two attributes, the \"context\" and \"qas\".\n",
        "\n",
        "context: The paragraph or text from which the question is asked.\n",
        "qas: A list of questions and answers (format below).\n",
        "Questions and answers are represented as dictionaries. Each dictionary in qas has the following format.\n",
        "\n",
        "id: (string) A unique ID for the question. Should be unique across the entire dataset.\n",
        "\n",
        "question: (string) A question.\n",
        "\n",
        "answers: (list) The list of correct answers to the question.\n",
        "\n",
        "Source: https://simpletransformers.ai/docs/qa-data-formats/"
      ],
      "metadata": {
        "id": "2eKxZhYQAEIS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the dataset and take a handful of examples\n",
        "\n",
        "count=25\n",
        "sample=data_squad['train'].shuffle(seed=1962).select(range(count))\n",
        "df=pd.DataFrame()\n",
        "df['answer'] = [answer['text'][0] for answer in sample['answers']]\n",
        "df['context'] = sample['context']\n",
        "df['question'] = sample['question']\n",
        "\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        },
        "id": "LgQ9B0FT3OmF",
        "outputId": "5ef362a0-eb58-485c-de83-ab85cb8b28fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /content/drive/MyDrive/w266 NLP Final Project/Data/squad.hf/train/cache-8ab9b6302b91254a.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     answer  \\\n",
              "0                         biotech companies   \n",
              "1                       Tytus Woyciechowski   \n",
              "2          the Endangered Species Committee   \n",
              "3                                     China   \n",
              "4                                  45 years   \n",
              "5      Cold War, First Gulf War, Kosovo War   \n",
              "6                                    Buddha   \n",
              "7                                      9.3%   \n",
              "8                             Improvisation   \n",
              "9                                      1861   \n",
              "10                                      40%   \n",
              "11         Event-based prospective memories   \n",
              "12                     dragonfly-like forms   \n",
              "13             the Shijing or Book of Songs   \n",
              "14                        Olympic Peninsula   \n",
              "15  transported along the canals and rivers   \n",
              "16                               base alone   \n",
              "17                                1031–1095   \n",
              "18                               Mechanical   \n",
              "19                          The Lamb of God   \n",
              "20                                     2.79   \n",
              "21                                    urban   \n",
              "22                                  parents   \n",
              "23       the proper aim point automatically   \n",
              "24                        Tarsus of Cilicia   \n",
              "\n",
              "                                              context  \\\n",
              "0   Prior to moving its headquarters to Chicago, a...   \n",
              "1   Four boarders at his parents' apartments becam...   \n",
              "2   The question to be answered is whether a liste...   \n",
              "3   In Asian countries such as China, Korea, and J...   \n",
              "4   Saint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/;...   \n",
              "5   Since 1947, Canadian military units have parti...   \n",
              "6   Tibet has various festivals that are commonly ...   \n",
              "7   From 2001 to 2008, Mac sales increased continu...   \n",
              "8   Improvisation stands at the centre of Chopin's...   \n",
              "9   Alfred North Whitehead was born in Ramsgate, K...   \n",
              "10  While Southeast Asia is rich in flora and faun...   \n",
              "11  Another major way to distinguish different mem...   \n",
              "12  Late Carboniferous and Early Permian insect or...   \n",
              "13  As a more urban culture developed, academies p...   \n",
              "14  Seattle is located between the saltwater Puget...   \n",
              "15  By the time of the Uruk period (c. 4100–2900 B...   \n",
              "16  Thermally, a temperate glacier is at melting p...   \n",
              "17  There are many notable contributors to the fie...   \n",
              "18  Two assumptions underpinned the British approa...   \n",
              "19  In Johannine \"agent Christology\" the submissio...   \n",
              "20  There were 46,917 households, out of which 7,8...   \n",
              "21  The Baker v. Carr (1962) decision of the US Su...   \n",
              "22  Home-based manufacturing operations were activ...   \n",
              "23  The solution was automation, in the form of a ...   \n",
              "24  In 1045, the Byzantine Empire conquered Bagrat...   \n",
              "\n",
              "                                             question  \n",
              "0   What type of businesses did Nickles want to at...  \n",
              "1   To whom did Chopin reveal in letters which par...  \n",
              "2   If a species may be harmed, who holds final sa...  \n",
              "3   What country has the dog as part of its 12 ani...  \n",
              "4                   How long did his episcopate last?  \n",
              "5   What are some of the wars the Canadian Militar...  \n",
              "6   What is worshipped during Tibet's various fest...  \n",
              "7   What was Apples market share of all computer s...  \n",
              "8                What is central to Chopin's process?  \n",
              "9                       What year was Whitehead born?  \n",
              "10  What percentage of plant and animal species ex...  \n",
              "11  If Bob realized he needed to mail his mother a...  \n",
              "12      What kind of giant insect form had wingspans?  \n",
              "13  What is an example of a collection of classic ...  \n",
              "14             What land area is west of Puget Sound?  \n",
              "15  How were trade goods transported in southern M...  \n",
              "16  From where is the temperature of a glacier mea...  \n",
              "17                           When was Shen Kuo alive?  \n",
              "18                    What kind of fuses were needed?  \n",
              "19              What is another name for Jesus given?  \n",
              "20            What was the total average family size?  \n",
              "21  Which type of geographical district became mor...  \n",
              "22                  Who did the children work beside?  \n",
              "23  What did the Predictor calculate after it was ...  \n",
              "24                      Where did Roupen find refuge?  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-903cf8fb-fde3-4757-9e93-15a712292606\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answer</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>biotech companies</td>\n",
              "      <td>Prior to moving its headquarters to Chicago, a...</td>\n",
              "      <td>What type of businesses did Nickles want to at...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tytus Woyciechowski</td>\n",
              "      <td>Four boarders at his parents' apartments becam...</td>\n",
              "      <td>To whom did Chopin reveal in letters which par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the Endangered Species Committee</td>\n",
              "      <td>The question to be answered is whether a liste...</td>\n",
              "      <td>If a species may be harmed, who holds final sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>China</td>\n",
              "      <td>In Asian countries such as China, Korea, and J...</td>\n",
              "      <td>What country has the dog as part of its 12 ani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>45 years</td>\n",
              "      <td>Saint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/;...</td>\n",
              "      <td>How long did his episcopate last?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Cold War, First Gulf War, Kosovo War</td>\n",
              "      <td>Since 1947, Canadian military units have parti...</td>\n",
              "      <td>What are some of the wars the Canadian Militar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Buddha</td>\n",
              "      <td>Tibet has various festivals that are commonly ...</td>\n",
              "      <td>What is worshipped during Tibet's various fest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9.3%</td>\n",
              "      <td>From 2001 to 2008, Mac sales increased continu...</td>\n",
              "      <td>What was Apples market share of all computer s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Improvisation</td>\n",
              "      <td>Improvisation stands at the centre of Chopin's...</td>\n",
              "      <td>What is central to Chopin's process?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1861</td>\n",
              "      <td>Alfred North Whitehead was born in Ramsgate, K...</td>\n",
              "      <td>What year was Whitehead born?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>40%</td>\n",
              "      <td>While Southeast Asia is rich in flora and faun...</td>\n",
              "      <td>What percentage of plant and animal species ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Event-based prospective memories</td>\n",
              "      <td>Another major way to distinguish different mem...</td>\n",
              "      <td>If Bob realized he needed to mail his mother a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>dragonfly-like forms</td>\n",
              "      <td>Late Carboniferous and Early Permian insect or...</td>\n",
              "      <td>What kind of giant insect form had wingspans?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>the Shijing or Book of Songs</td>\n",
              "      <td>As a more urban culture developed, academies p...</td>\n",
              "      <td>What is an example of a collection of classic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Olympic Peninsula</td>\n",
              "      <td>Seattle is located between the saltwater Puget...</td>\n",
              "      <td>What land area is west of Puget Sound?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>transported along the canals and rivers</td>\n",
              "      <td>By the time of the Uruk period (c. 4100–2900 B...</td>\n",
              "      <td>How were trade goods transported in southern M...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>base alone</td>\n",
              "      <td>Thermally, a temperate glacier is at melting p...</td>\n",
              "      <td>From where is the temperature of a glacier mea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1031–1095</td>\n",
              "      <td>There are many notable contributors to the fie...</td>\n",
              "      <td>When was Shen Kuo alive?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Mechanical</td>\n",
              "      <td>Two assumptions underpinned the British approa...</td>\n",
              "      <td>What kind of fuses were needed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>The Lamb of God</td>\n",
              "      <td>In Johannine \"agent Christology\" the submissio...</td>\n",
              "      <td>What is another name for Jesus given?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2.79</td>\n",
              "      <td>There were 46,917 households, out of which 7,8...</td>\n",
              "      <td>What was the total average family size?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>urban</td>\n",
              "      <td>The Baker v. Carr (1962) decision of the US Su...</td>\n",
              "      <td>Which type of geographical district became mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>parents</td>\n",
              "      <td>Home-based manufacturing operations were activ...</td>\n",
              "      <td>Who did the children work beside?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>the proper aim point automatically</td>\n",
              "      <td>The solution was automation, in the form of a ...</td>\n",
              "      <td>What did the Predictor calculate after it was ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Tarsus of Cilicia</td>\n",
              "      <td>In 1045, the Byzantine Empire conquered Bagrat...</td>\n",
              "      <td>Where did Roupen find refuge?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-903cf8fb-fde3-4757-9e93-15a712292606')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-903cf8fb-fde3-4757-9e93-15a712292606 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-903cf8fb-fde3-4757-9e93-15a712292606');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUebML35BsO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source: https://huggingface.co/ZhangCheng/T5v1.1-Base-Fine-Tuned-for-Question-Generation?text=%3Canswer%3E+thousands+%3Ccontext%3E+Transformers+provides+thousands+of+pre-trained+models+to+perform+tasks+on+different+modalities+such+as+text%2C+vision%2C+and+audio.\n"
      ],
      "metadata": {
        "id": "hrqFsWY0BsrP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 1"
      ],
      "metadata": {
        "id": "Q3g8GejKF4k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text to test from dataset\n",
        "answer = df.answer[0]\n",
        "context = df.context[0]\n",
        "task = \"qg\"\n",
        "\n",
        "input_text = f\"{task} answer: {answer} </s> context: {context}\"\n",
        "\n",
        "output_text = df.question[0]"
      ],
      "metadata": {
        "id": "YVbbz4cT31-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text is answer and context\n",
        "input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "B2NDmUwk4-KL",
        "outputId": "007f2d91-debb-436a-da46-fc8470dd96ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"qg answer: biotech companies </s> context: Prior to moving its headquarters to Chicago, aerospace manufacturer Boeing (#30) was the largest company based in Seattle. Its largest division is still headquartered in nearby Renton, and the company has large aircraft manufacturing plants in Everett and Renton, so it remains the largest private employer in the Seattle metropolitan area. Former Seattle Mayor Greg Nickels announced a desire to spark a new economic boom driven by the biotechnology industry in 2006. Major redevelopment of the South Lake Union neighborhood is underway, in an effort to attract new and established biotech companies to the city, joining biotech companies Corixa (acquired by GlaxoSmithKline), Immunex (now part of Amgen), Trubion, and ZymoGenetics. Vulcan Inc., the holding company of billionaire Paul Allen, is behind most of the development projects in the region. While some see the new development as an economic boon, others have criticized Nickels and the Seattle City Council for pandering to Allen's interests at taxpayers' expense. Also in 2006, Expansion Magazine ranked Seattle among the top 10 metropolitan areas in the nation for climates favorable to business expansion. In 2005, Forbes ranked Seattle as the most expensive American city for buying a house based on the local income levels. In 2013, however, the magazine ranked Seattle No. 9 on its list of the Best Places for Business and Careers.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired output text is a question\n",
        "output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "s_zagFCf4_an",
        "outputId": "f968fbad-b78b-472d-baf0-4e60999010e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What type of businesses did Nickles want to attract to Seattle?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "inputs = tokenizer(input_text, max_length=1024, truncation=True, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "OwFscF8M5FbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check tokenized inputs\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MYUqW7j5Fdl",
        "outputId": "a50cc40f-e2f1-484f-e54c-581a5131cb25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 318), dtype=int32, numpy=\n",
              "array([[    3,  1824,   122,  1525,    10,  2392,  3470,   688,     1,\n",
              "         2625,    10,  6783,    12,  1735,   165, 13767,    12,  3715,\n",
              "            6, 28674,  4818, 21430,    41,  4663,  1458,    61,    47,\n",
              "            8,  2015,   349,     3,   390,    16,  8854,     5,    94,\n",
              "            7,  2015,  4889,    19,   341,     3, 27630,    16,  4676,\n",
              "         9405,   106,     6,    11,     8,   349,    65,   508,  6442,\n",
              "         3732,  2677,    16,  6381,    15,    17,    17,    11,  9405,\n",
              "          106,     6,    78,    34,  3048,     8,  2015,  1045,  6152,\n",
              "           16,     8,  8854, 25233,   616,     5, 18263,  8854, 12394,\n",
              "        11859, 29005,     7,  2162,     3,     9,  3667,    12, 13233,\n",
              "            3,     9,   126,  1456, 13997,  6737,    57,     8,  2392,\n",
              "        18485,   681,    16, 15066,  9236,     3,    60, 19677,    13,\n",
              "            8,  1013,  2154,  3545,  5353,    19, 18953,     6,    16,\n",
              "           46,  1941,    12,  5521,   126,    11,  2127,  2392,  3470,\n",
              "          688,    12,     8,   690,     6,  6109,  2392,  3470,   688,\n",
              "         2487,  2407,     9,    41,     9,    75,  1169,  1271,    57,\n",
              "        10941,   226,    32, 30077,   439,   747,   201, 18502,   994,\n",
              "           41,  7651,   294,    13,   736,   729,   201,  7953,  6420,\n",
              "           29,     6,    11,  1027,    63,    51,    32, 13714,  7578,\n",
              "            7,     5,   584,    83,  1608,  1542,     5,     6,     8,\n",
              "         3609,   349,    13,  2108,  2378,  1838, 10618,     6,    19,\n",
              "         1187,   167,    13,     8,   606,  1195,    16,     8,  1719,\n",
              "            5,   818,   128,   217,     8,   126,   606,    38,    46,\n",
              "         1456,  3005,   106,     6,   717,    43,     3, 27624, 29005,\n",
              "            7,    11,     8,  8854,   896,  2063,    21,  2131,   588,\n",
              "           53,    12, 10618,    31,     7,  3984,    44, 15375,     7,\n",
              "           31,  8225,     5,  1203,    16,  3581,     6,  1881,  2837,\n",
              "         1938,  8336,     3,  8232,  8854,   859,     8,   420,   335,\n",
              "        25233,   844,    16,     8,  2982,    21,  3298,     7, 15229,\n",
              "           12,   268,  5919,     5,    86,  3105,     6, 24852,     3,\n",
              "         8232,  8854,    38,     8,   167,  2881,   797,   690,    21,\n",
              "         2611,     3,     9,   629,     3,   390,    30,     8,   415,\n",
              "         2055,  1425,     5,    86,  7218,   983,     6,     8,  3835,\n",
              "            3,  8232,  8854,   465,     5,   668,    30,   165,   570,\n",
              "           13,     8,  1648,  3399,     7,    21,  1769,    11, 15151,\n",
              "            7,     5,     1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 318), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate question output\n",
        "outputs = model.generate(input_ids = inputs['input_ids'],\n",
        "                         attention_mask = inputs['attention_mask'])\n",
        "\n",
        "question_output = pprint(tokenizer.batch_decode(outputs, \n",
        "                                                skip_special_tokens=True, \n",
        "                                                clean_up_tokenization_spaces=True\n",
        "                                                )[0], compact=True)\n",
        "\n",
        "question_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zzIzsFxEL2e",
        "outputId": "d47ce7e0-a505-4d51-f740-acabb0ea358e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'. Boeing (#30) was founded in Seattle in 1931. Boeing (#'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example 6"
      ],
      "metadata": {
        "id": "YP-R2UTFGFaE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text to test from dataset\n",
        "answer = df.answer[6]\n",
        "context = df.context[6]\n",
        "task = \"qg\"\n",
        "\n",
        "input_text = f\"{task} answer: {answer} </s> context: {context}\"\n",
        "\n",
        "output_text = df.question[6]"
      ],
      "metadata": {
        "id": "EpUbWffREL5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text is answer and context\n",
        "input_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "6izArrqBEL7c",
        "outputId": "81e33c2b-caad-4d07-c8c8-726952595ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"qg answer: Buddha </s> context: Tibet has various festivals that are commonly performed to worship the Buddha[citation needed] throughout the year. Losar is the Tibetan New Year Festival. Preparations for the festive event are manifested by special offerings to family shrine deities, painted doors with religious symbols, and other painstaking jobs done to prepare for the event. Tibetans eat Guthuk (barley noodle soup with filling) on New Year's Eve with their families. The Monlam Prayer Festival follows it in the first month of the Tibetan calendar, falling between the fourth and the eleventh days of the first Tibetan month. It involves dancing and participating in sports events, as well as sharing picnics. The event was established in 1049 by Tsong Khapa, the founder of the Dalai Lama and the Panchen Lama's order.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desired output text is a question\n",
        "output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G-IwidI0EL-I",
        "outputId": "bede4ffe-66f5-4eb0-e73e-ba01250aea65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is worshipped during Tibet's various festibals?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "inputs = tokenizer(input_text, max_length=1024, truncation=True, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "Rcrla6LgCMV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check tokenized inputs\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdqZM7VGGTyc",
        "outputId": "f6ac959d-596b-4f0c-ca34-8fae90ff58c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 188), dtype=int32, numpy=\n",
              "array([[    3,  1824,   122,  1525,    10, 21554,     1,  2625,    10,\n",
              "        28920,    65,   796, 14856,    24,    33,  5871,  3032,    12,\n",
              "         7373,     8, 21554,  6306, 13903,   906,   908,  1019,     8,\n",
              "          215,     5,  3144,   291,    19,     8, 26488,   368,  2929,\n",
              "         3397,     5,  1266,  1893,  1628,    21,     8, 15723,   605,\n",
              "           33,  6571,    15,    26,    57,   534, 11571,    12,   384,\n",
              "        30258,    20,  2197,     6,  7445,  3377,    28,  4761, 13619,\n",
              "            6,    11,   119,  1406,     7, 14867,  2476,   612,    12,\n",
              "         2967,    21,     8,   605,     5, 26488,     7,     3,  1544,\n",
              "         2846,   189,  1598,    41,  1047,  1306,     3,    29, 14957,\n",
              "         5759,    28,    14,    53,    61,    30,   368,  2929,    31,\n",
              "            7, 11566,    28,    70,  1791,     5,    37,  2963,    40,\n",
              "          265, 23535,  3397,  6963,    34,    16,     8,   166,   847,\n",
              "           13,     8, 26488,  4793,     6,  7306,   344,     8,  4509,\n",
              "           11,     8, 20394,   189,   477,    13,     8,   166, 26488,\n",
              "          847,     5,    94,  5806, 10410,    11,  7448,    16,  2100,\n",
              "          984,     6,    38,   168,    38,  2178, 13791,     7,     5,\n",
              "           37,   605,    47,  2127,    16,   335,  3647,    57,   332,\n",
              "            7,  2444, 12877,   102,     9,     6,     8,  7174,    13,\n",
              "            8, 10729,     9,    23, 15763,     9,    11,     8,  4266,\n",
              "         1559, 15763,     9,    31,     7,   455,     5,     1]],\n",
              "      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 188), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate question output\n",
        "outputs = model.generate(input_ids = inputs['input_ids'],\n",
        "                         attention_mask = inputs['attention_mask'])\n",
        "\n",
        "question_output = pprint(tokenizer.batch_decode(outputs, \n",
        "                                                skip_special_tokens=True, \n",
        "                                                clean_up_tokenization_spaces=True\n",
        "                                                )[0], compact=True)\n",
        "\n",
        "question_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DruDnlr4GT0u",
        "outputId": "8e3aea04-e0d2-43e9-fe7e-d2104e592752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('the Tibetan New Year. The Tibetan New Year is celebrated in the month of '\n",
            " 'January.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfR9nl7DGT3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVa8FlGYGT5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try training the model\n",
        "\n",
        "Source: https://huggingface.co/docs/transformers/model_doc/t5#transformers.TFT5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "7cyQH-uEbyca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Come up with a prompt for T5 model\n",
        "prompt = 'question_gen: '\n",
        "# Add \"answer: \" to each answer in list\n",
        "# answer = [\"question_gen: answer: \" + a for a in df.answer]\n",
        "# Add \"context: \" to each context in list\n",
        "context = [\"context: \" + c for c in df.context]\n",
        "# Add \"question: \" to each question in list\n",
        "question = [\"question: \" + q for q in df.question]\n",
        "\n",
        "# Input text will be prompt + answer + context\n",
        "input_txt = [prompt + x for x in context]\n",
        "\n",
        "# Output text will be questions\n",
        "output_txt = question\n",
        "\n",
        "input_txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCWc7T-ucFpT",
        "outputId": "fe8aaa20-bcc1-4fd4-844b-e4169736671c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"question_gen: context: Prior to moving its headquarters to Chicago, aerospace manufacturer Boeing (#30) was the largest company based in Seattle. Its largest division is still headquartered in nearby Renton, and the company has large aircraft manufacturing plants in Everett and Renton, so it remains the largest private employer in the Seattle metropolitan area. Former Seattle Mayor Greg Nickels announced a desire to spark a new economic boom driven by the biotechnology industry in 2006. Major redevelopment of the South Lake Union neighborhood is underway, in an effort to attract new and established biotech companies to the city, joining biotech companies Corixa (acquired by GlaxoSmithKline), Immunex (now part of Amgen), Trubion, and ZymoGenetics. Vulcan Inc., the holding company of billionaire Paul Allen, is behind most of the development projects in the region. While some see the new development as an economic boon, others have criticized Nickels and the Seattle City Council for pandering to Allen's interests at taxpayers' expense. Also in 2006, Expansion Magazine ranked Seattle among the top 10 metropolitan areas in the nation for climates favorable to business expansion. In 2005, Forbes ranked Seattle as the most expensive American city for buying a house based on the local income levels. In 2013, however, the magazine ranked Seattle No. 9 on its list of the Best Places for Business and Careers.\",\n",
              " 'question_gen: context: Four boarders at his parents\\' apartments became Chopin\\'s intimates: Tytus Woyciechowski, Jan Nepomucen Białobłocki, Jan Matuszyński and Julian Fontana; the latter two would become part of his Paris milieu. He was friendly with members of Warsaw\\'s young artistic and intellectual world, including Fontana, Józef Bohdan Zaleski and Stefan Witwicki. He was also attracted to the singing student Konstancja Gładkowska. In letters to Woyciechowski, he indicated which of his works, and even which of their passages, were influenced by his fascination with her; his letter of 15 May 1830 revealed that the slow movement (Larghetto) of his Piano Concerto No. 1 (in E minor) was secretly dedicated to her – \"It should be like dreaming in beautiful springtime – by moonlight.\" His final Conservatory report (July 1829) read: \"Chopin F., third-year student, exceptional talent, musical genius.\"',\n",
              " 'question_gen: context: The question to be answered is whether a listed species will be harmed by the action and, if so, how the harm can be minimized. If harm cannot be avoided, the project agency can seek an exemption from the Endangered Species Committee, an ad hoc panel composed of members from the executive branch and at least one appointee from the state where the project is to occur. Five of the seven committee members must vote for the exemption to allow taking (to harass, harm, pursue, hunt, shoot, wound, kill, trap, capture, or collect, or significant habitat modification, or to attempt to engage in any such conduct) of listed species.',\n",
              " 'question_gen: context: In Asian countries such as China, Korea, and Japan, dogs are viewed as kind protectors. The role of the dog in Chinese mythology includes a position as one of the twelve animals which cyclically represent years (the zodiacal dog).',\n",
              " 'question_gen: context: Saint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/; Greek: Ἀθανάσιος Ἀλεξανδρείας, Athanásios Alexandrías; c. 296–298 – 2 May 373), also called Athanasius the Great, Athanasius the Confessor or, primarily in the Coptic Orthodox Church, Athanasius the Apostolic, was the twentieth bishop of Alexandria (as Athanasius I). His episcopate lasted 45 years (c. 8 June 328 – 2 May 373), of which over 17 were spent in five exiles ordered by four different Roman emperors. Athanasius is a renowned Christian theologian, a Church Father, the chief defender of Trinitarianism against Arianism, and a noted Egyptian leader of the fourth century.',\n",
              " \"question_gen: context: Since 1947, Canadian military units have participated in more than 200 operations worldwide, and completed 72 international operations. Canadian soldiers, sailors, and aviators came to be considered world-class professionals through conspicuous service during these conflicts and the country's integral participation in NATO during the Cold War, First Gulf War, Kosovo War, and in United Nations Peacekeeping operations, such as the Suez Crisis, Golan Heights, Cyprus, Croatia, Bosnia, Afghanistan, and Libya. Canada maintained an aircraft carrier from 1957 to 1970 during the Cold War, which never saw combat but participated in patrols during the Cuban Missile Crisis.\",\n",
              " \"question_gen: context: Tibet has various festivals that are commonly performed to worship the Buddha[citation needed] throughout the year. Losar is the Tibetan New Year Festival. Preparations for the festive event are manifested by special offerings to family shrine deities, painted doors with religious symbols, and other painstaking jobs done to prepare for the event. Tibetans eat Guthuk (barley noodle soup with filling) on New Year's Eve with their families. The Monlam Prayer Festival follows it in the first month of the Tibetan calendar, falling between the fourth and the eleventh days of the first Tibetan month. It involves dancing and participating in sports events, as well as sharing picnics. The event was established in 1049 by Tsong Khapa, the founder of the Dalai Lama and the Panchen Lama's order.\",\n",
              " \"question_gen: context: From 2001 to 2008, Mac sales increased continuously on an annual basis. Apple reported worldwide sales of 3.36 million Macs during the 2009 holiday season. As of Mid-2011, the Macintosh continues to enjoy rapid market share increase in the US, growing from 7.3% of all computer shipments in 2010 to 9.3% in 2011. According to IDC's quarterly PC tracker, globally, in 3rd quarter of 2014, Apple's PC market share increased 5.7 percent year over year, with record sales of 5.5 million units. Apple now sits in the number five spot, with a global market share of about 6% during 2014, behind Lenovo, HP, Dell and Acer.\",\n",
              " 'question_gen: context: Improvisation stands at the centre of Chopin\\'s creative processes. However, this does not imply impulsive rambling: Nicholas Temperley writes that \"improvisation is designed for an audience, and its starting-point is that audience\\'s expectations, which include the current conventions of musical form.\" The works for piano and orchestra, including the two concertos, are held by Temperley to be \"merely vehicles for brilliant piano playing ... formally longwinded and extremely conservative\". After the piano concertos (which are both early, dating from 1830), Chopin made no attempts at large-scale multi-movement forms, save for his late sonatas for piano and for cello; \"instead he achieved near-perfection in pieces of simple general design but subtle and complex cell-structure.\" Rosen suggests that an important aspect of Chopin\\'s individuality is his flexible handling of the four-bar phrase as a structural unit.',\n",
              " \"question_gen: context: Alfred North Whitehead was born in Ramsgate, Kent, England, in 1861. His father, Alfred Whitehead, was a minister and schoolmaster of Chatham House Academy, a successful school for boys established by Thomas Whitehead, Alfred North's grandfather. Whitehead himself recalled both of them as being very successful schoolmasters, but that his grandfather was the more extraordinary man. Whitehead's mother was Maria Sarah Whitehead, formerly Maria Sarah Buckmaster. Whitehead was apparently not particularly close with his mother, as he never mentioned her in any of his writings, and there is evidence that Whitehead's wife, Evelyn, had a low opinion of her.\",\n",
              " 'question_gen: context: While Southeast Asia is rich in flora and fauna, Southeast Asia is facing severe deforestation which causes habitat loss for various endangered species such as orangutan and the Sumatran tiger. Predictions have been made that more than 40% of the animal and plant species in Southeast Asia could be wiped out in the 21st century. At the same time, haze has been a regular occurrence. The two worst regional hazes were in 1997 and 2006 in which multiple countries were covered with thick haze, mostly caused by \"slash and burn\" activities in Sumatra and Borneo. In reaction, several countries in Southeast Asia signed the ASEAN Agreement on Transboundary Haze Pollution to combat haze pollution.',\n",
              " 'question_gen: context: Another major way to distinguish different memory functions is whether the content to be remembered is in the past, retrospective memory, or in the future, prospective memory. Thus, retrospective memory as a category includes semantic, episodic and autobiographical memory. In contrast, prospective memory is memory for future intentions, or remembering to remember (Winograd, 1988). Prospective memory can be further broken down into event- and time-based prospective remembering. Time-based prospective memories are triggered by a time-cue, such as going to the doctor (action) at 4pm (cue). Event-based prospective memories are intentions triggered by cues, such as remembering to post a letter (action) after seeing a mailbox (cue). Cues do not need to be related to the action (as the mailbox/letter example), and lists, sticky-notes, knotted handkerchiefs, or string around the finger all exemplify cues that people use as strategies to enhance prospective memory.',\n",
              " 'question_gen: context: Late Carboniferous and Early Permian insect orders include both extant groups, their stem groups, and a number of Paleozoic groups, now extinct. During this era, some giant dragonfly-like forms reached wingspans of 55 to 70 cm (22 to 28 in), making them far larger than any living insect. This gigantism may have been due to higher atmospheric oxygen levels that allowed increased respiratory efficiency relative to today. The lack of flying vertebrates could have been another factor. Most extinct orders of insects developed during the Permian period that began around 270 million years ago. Many of the early groups became extinct during the Permian-Triassic extinction event, the largest mass extinction in the history of the Earth, around 252 million years ago.',\n",
              " 'question_gen: context: As a more urban culture developed, academies provided a means of transmission for speculative and philosophical literature in early civilizations, resulting in the prevalence of literature in Ancient China, Ancient India, Persia and Ancient Greece and Rome. Many works of earlier periods, even in narrative form, had a covert moral or didactic purpose, such as the Sanskrit Panchatantra or the Metamorphoses of Ovid. Drama and satire also developed as urban culture provided a larger public audience, and later readership, for literary production. Lyric poetry (as opposed to epic poetry) was often the speciality of courts and aristocratic circles, particularly in East Asia where songs were collected by the Chinese aristocracy as poems, the most notable being the Shijing or Book of Songs. Over a long period, the poetry of popular pre-literate balladry and song interpenetrated and eventually influenced poetry in the literary medium.',\n",
              " \"question_gen: context: Seattle is located between the saltwater Puget Sound (an arm of the Pacific Ocean) to the west and Lake Washington to the east. The city's chief harbor, Elliott Bay, is part of Puget Sound, which makes the city an oceanic port. To the west, beyond Puget Sound, are the Kitsap Peninsula and Olympic Mountains on the Olympic Peninsula; to the east, beyond Lake Washington and the eastside suburbs, are Lake Sammamish and the Cascade Range. Lake Washington's waters flow to Puget Sound through the Lake Washington Ship Canal (consisting of two man-made canals, Lake Union, and the Hiram M. Chittenden Locks at Salmon Bay, ending in Shilshole Bay on Puget Sound).\",\n",
              " 'question_gen: context: By the time of the Uruk period (c. 4100–2900 BC calibrated), the volume of trade goods transported along the canals and rivers of southern Mesopotamia facilitated the rise of many large, stratified, temple-centered cities (with populations of over 10,000 people) where centralized administrations employed specialized workers. It is fairly certain that it was during the Uruk period that Sumerian cities began to make use of slave labor captured from the hill country, and there is ample evidence for captured slaves as workers in the earliest texts. Artifacts, and even colonies of this Uruk civilization have been found over a wide area—from the Taurus Mountains in Turkey, to the Mediterranean Sea in the west, and as far east as central Iran.',\n",
              " 'question_gen: context: Thermally, a temperate glacier is at melting point throughout the year, from its surface to its base. The ice of a polar glacier is always below freezing point from the surface to its base, although the surface snowpack may experience seasonal melting. A sub-polar glacier includes both temperate and polar ice, depending on depth beneath the surface and position along the length of the glacier. In a similar way, the thermal regime of a glacier is often described by the temperature at its base alone. A cold-based glacier is below freezing at the ice-ground interface, and is thus frozen to the underlying substrate. A warm-based glacier is above or at freezing at the interface, and is able to slide at this contact. This contrast is thought to a large extent to govern the ability of a glacier to effectively erode its bed, as sliding ice promotes plucking at rock from the surface below. Glaciers which are partly cold-based and partly warm-based are known as polythermal.',\n",
              " \"question_gen: context: There are many notable contributors to the field of Chinese science throughout the ages. One of the best examples would be Shen Kuo (1031–1095), a polymath scientist and statesman who was the first to describe the magnetic-needle compass used for navigation, discovered the concept of true north, improved the design of the astronomical gnomon, armillary sphere, sight tube, and clepsydra, and described the use of drydocks to repair boats. After observing the natural process of the inundation of silt and the find of marine fossils in the Taihang Mountains (hundreds of miles from the Pacific Ocean), Shen Kuo devised a theory of land formation, or geomorphology. He also adopted a theory of gradual climate change in regions over time, after observing petrified bamboo found underground at Yan'an, Shaanxi province. If not for Shen Kuo's writing, the architectural works of Yu Hao would be little known, along with the inventor of movable type printing, Bi Sheng (990-1051). Shen's contemporary Su Song (1020–1101) was also a brilliant polymath, an astronomer who created a celestial atlas of star maps, wrote a pharmaceutical treatise with related subjects of botany, zoology, mineralogy, and metallurgy, and had erected a large astronomical clocktower in Kaifeng city in 1088. To operate the crowning armillary sphere, his clocktower featured an escapement mechanism and the world's oldest known use of an endless power-transmitting chain drive.\",\n",
              " 'question_gen: context: Two assumptions underpinned the British approach to HAA fire; first, aimed fire was the primary method and this was enabled by predicting gun data from visually tracking the target and having its height. Second, that the target would maintain a steady course, speed and height. This HAA was to engage targets up to 24,000 feet. Mechanical, as opposed to igniferous, time fuses were required because the speed of powder burning varied with height so fuse length was not a simple function of time of flight. Automated fire ensured a constant rate of fire that made it easier to predict where each shell should be individually aimed.',\n",
              " 'question_gen: context: In Johannine \"agent Christology\" the submission of Jesus to crucifixion is a sacrifice made as an agent of God or servant of God, for the sake of eventual victory. This builds on the salvific theme of the Gospel of John which begins in John 1:29 with John the Baptist\\'s proclamation: \"The Lamb of God who takes away the sins of the world\". Further reinforcement of the concept is provided in Revelation 21:14 where the \"lamb slain but standing\" is the only one worthy of handling the scroll (i.e. the book) containing the names of those who are to be saved.',\n",
              " 'question_gen: context: There were 46,917 households, out of which 7,835 (16.7%) had children under the age of 18 living in them, 13,092 (27.9%) were opposite-sex married couples living together, 3,510 (7.5%) had a female householder with no husband present, 1,327 (2.8%) had a male householder with no wife present. There were 2,867 (6.1%) unmarried opposite-sex partnerships, and 416 (0.9%) same-sex married couples or partnerships. 22,716 households (48.4%) were made up of individuals and 5,551 (11.8%) had someone living alone who was 65 years of age or older. The average household size was 1.87. There were 17,929 families (38.2% of all households); the average family size was 2.79.',\n",
              " 'question_gen: context: The Baker v. Carr (1962) decision of the US Supreme Court established the principle of \"one man, one vote\", requiring state legislatures to redistrict to bring Congressional apportionment in line with decennial censuses. It also required both houses of state legislatures to be based on population for representation and not geographic districts such as counties. This case arose out of a lawsuit challenging the longstanding rural bias of apportionment of seats in the Tennessee legislature. After decades in which urban populations had been underrepresented in many state legislatures, this significant ruling led to an increased (and proportional) prominence in state politics by urban and, eventually, suburban, legislators and statewide officeholders in relation to their population within the state. The ruling also applied to numerous other states long controlled by rural minorities, such as Alabama, Vermont, and Montana.',\n",
              " 'question_gen: context: Home-based manufacturing operations were active year round. Families willingly deployed their children in these income generating home enterprises. In many cases, men worked from home. In France, over 58 percent of garment workers operated out of their homes; in Germany, the number of full-time home operations nearly doubled between 1882 and 1907; and in the United States, millions of families operated out of home seven days a week, year round to produce garments, shoes, artificial flowers, feathers, match boxes, toys, umbrellas and other products. Children aged 5–14 worked alongside the parents. Home-based operations and child labour in Australia, Britain, Austria and other parts of the world was common. Rural areas similarly saw families deploying their children in agriculture. In 1946, Frieda Miller - then Director of United States Department of Labour - told the International Labour Organisation that these home-based operations offered, \"low wages, long hours, child labour, unhealthy and insanitary working conditions.\"',\n",
              " 'question_gen: context: The solution was automation, in the form of a mechanical computer, the Kerrison Predictor. Operators kept it pointed at the target, and the Predictor then calculated the proper aim point automatically and displayed it as a pointer mounted on the gun. The gun operators simply followed the pointer and loaded the shells. The Kerrison was fairly simple, but it pointed the way to future generations that incorporated radar, first for ranging and later for tracking. Similar predictor systems were introduced by Germany during the war, also adding radar ranging as the war progressed.',\n",
              " 'question_gen: context: In 1045, the Byzantine Empire conquered Bagratid Armenia. Soon, the other Armenian states fell under Byzantine control as well. The Byzantine rule was short lived, as in 1071 Seljuk Turks defeated the Byzantines and conquered Armenia at the Battle of Manzikert, establishing the Seljuk Empire. To escape death or servitude at the hands of those who had assassinated his relative, Gagik II, King of Ani, an Armenian named Roupen, went with some of his countrymen into the gorges of the Taurus Mountains and then into Tarsus of Cilicia. The Byzantine governor of the palace gave them shelter where the Armenian Kingdom of Cilicia was eventually established on 6 January 1198 under King Leo I, a descendant of Prince Roupen.']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXFseZ7DcTb2",
        "outputId": "f3c62193-8e9c-4bcd-eb28-d87a65b383f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['question: What type of businesses did Nickles want to attract to Seattle?',\n",
              " 'question: To whom did Chopin reveal in letters which parts of his work were about the singing student he was infatuated with?',\n",
              " 'question: If a species may be harmed, who holds final say on whether the project may proceed?',\n",
              " 'question: What country has the dog as part of its 12 animals that represent years?',\n",
              " 'question: How long did his episcopate last?',\n",
              " 'question: What are some of the wars the Canadian Military was involved in?',\n",
              " \"question: What is worshipped during Tibet's various festibals?\",\n",
              " 'question: What was Apples market share of all computer shipments in 2011?',\n",
              " \"question: What is central to Chopin's process?\",\n",
              " 'question: What year was Whitehead born?',\n",
              " 'question: What percentage of plant and animal species extinction is predicted in the 21st century?',\n",
              " 'question: If Bob realized he needed to mail his mother a letter after seeing the postal office, which kind of memory did he trigger?',\n",
              " 'question: What kind of giant insect form had wingspans?',\n",
              " 'question: What is an example of a collection of classic Chinese lyric poetry?',\n",
              " 'question: What land area is west of Puget Sound?',\n",
              " 'question: How were trade goods transported in southern Mesopotamia?',\n",
              " 'question: From where is the temperature of a glacier measured?',\n",
              " 'question: When was Shen Kuo alive?',\n",
              " 'question: What kind of fuses were needed?',\n",
              " 'question: What is another name for Jesus given?',\n",
              " 'question: What was the total average family size?',\n",
              " 'question: Which type of geographical district became more powerful in Tennessee politics following the 1962 Supreme Court decision?',\n",
              " 'question: Who did the children work beside?',\n",
              " 'question: What did the Predictor calculate after it was pointed at a target?',\n",
              " 'question: Where did Roupen find refuge?']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "inputs = tokenizer(input_txt, max_length=1024, padding=True, truncation=True, return_tensors=\"tf\").input_ids\n",
        "labels = tokenizer(output_txt, max_length=1024, padding=True, truncation=True, return_tensors=\"tf\").input_ids\n",
        "outputs = model(inputs, labels=labels)\n",
        "loss = outputs.loss\n",
        "logits = outputs.logits"
      ],
      "metadata": {
        "id": "V-xo7xLeGT8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "inputs = tokenizer(\n",
        "    \"In Asian countries such as China, Korea, and Japan, dogs are viewed as kind protectors. The role of the dog in Chinese mythology includes a position as one of the twelve animals which cyclically represent years (the zodiacal dog).\", return_tensors=\"tf\"\n",
        ").input_ids  # Batch size 1\n",
        "\n",
        "outputs = model.generate(inputs)\n",
        "\n",
        "print(tokenizer.decode(outputs[0]\n",
        "                       , skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2GsJqdAb04I",
        "outputId": "b1e0df43-8d3e-4a11-8c64-268488d52e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py:1695: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the zodiacal dog. Dogs are protectors of the home. Dogs are\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Not generate model with more sophistication (kind of)\n",
        "soph_outputs = model.generate(inputs,\n",
        "                              num_beams=2,\n",
        "                              no_repeat_ngram_size=1,\n",
        "                              min_length=20,\n",
        "                              max_length=40)\n",
        "                             \n",
        "print([tokenizer.decode(x, skip_special_tokens=True, \n",
        "                           clean_up_tokenization_spaces=False) for x in soph_outputs])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txuBhjrRcHsD",
        "outputId": "5a4604de-2016-4aa9-8335-36acb9691d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the zodiacal dog. Dogs are viewed as protector of humans and animals in general,?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JuhGTzgtb06w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xK1Y7O8bb09W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYY8RXw_b0_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvH_8yb2b1Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try running more data through model"
      ],
      "metadata": {
        "id": "tplXCuoBJFe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = 'qg: '\n",
        "answer = df.answer\n",
        "context = df.context\n",
        "\n",
        "input_txt = [prompt + sequence for sequence in answer + context]\n",
        "\n",
        "output_txt = df.question"
      ],
      "metadata": {
        "id": "2RvT9zsnH-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcQECRh-H-Pn",
        "outputId": "ab7e3490-9cff-4939-dcaa-9e0d2bf7a3b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"qg: biotech companiesPrior to moving its headquarters to Chicago, aerospace manufacturer Boeing (#30) was the largest company based in Seattle. Its largest division is still headquartered in nearby Renton, and the company has large aircraft manufacturing plants in Everett and Renton, so it remains the largest private employer in the Seattle metropolitan area. Former Seattle Mayor Greg Nickels announced a desire to spark a new economic boom driven by the biotechnology industry in 2006. Major redevelopment of the South Lake Union neighborhood is underway, in an effort to attract new and established biotech companies to the city, joining biotech companies Corixa (acquired by GlaxoSmithKline), Immunex (now part of Amgen), Trubion, and ZymoGenetics. Vulcan Inc., the holding company of billionaire Paul Allen, is behind most of the development projects in the region. While some see the new development as an economic boon, others have criticized Nickels and the Seattle City Council for pandering to Allen's interests at taxpayers' expense. Also in 2006, Expansion Magazine ranked Seattle among the top 10 metropolitan areas in the nation for climates favorable to business expansion. In 2005, Forbes ranked Seattle as the most expensive American city for buying a house based on the local income levels. In 2013, however, the magazine ranked Seattle No. 9 on its list of the Best Places for Business and Careers.\",\n",
              " 'qg: Tytus WoyciechowskiFour boarders at his parents\\' apartments became Chopin\\'s intimates: Tytus Woyciechowski, Jan Nepomucen Białobłocki, Jan Matuszyński and Julian Fontana; the latter two would become part of his Paris milieu. He was friendly with members of Warsaw\\'s young artistic and intellectual world, including Fontana, Józef Bohdan Zaleski and Stefan Witwicki. He was also attracted to the singing student Konstancja Gładkowska. In letters to Woyciechowski, he indicated which of his works, and even which of their passages, were influenced by his fascination with her; his letter of 15 May 1830 revealed that the slow movement (Larghetto) of his Piano Concerto No. 1 (in E minor) was secretly dedicated to her – \"It should be like dreaming in beautiful springtime – by moonlight.\" His final Conservatory report (July 1829) read: \"Chopin F., third-year student, exceptional talent, musical genius.\"',\n",
              " 'qg: the Endangered Species CommitteeThe question to be answered is whether a listed species will be harmed by the action and, if so, how the harm can be minimized. If harm cannot be avoided, the project agency can seek an exemption from the Endangered Species Committee, an ad hoc panel composed of members from the executive branch and at least one appointee from the state where the project is to occur. Five of the seven committee members must vote for the exemption to allow taking (to harass, harm, pursue, hunt, shoot, wound, kill, trap, capture, or collect, or significant habitat modification, or to attempt to engage in any such conduct) of listed species.',\n",
              " 'qg: ChinaIn Asian countries such as China, Korea, and Japan, dogs are viewed as kind protectors. The role of the dog in Chinese mythology includes a position as one of the twelve animals which cyclically represent years (the zodiacal dog).',\n",
              " 'qg: 45 yearsSaint Athanasius of Alexandria (/ˌæθəˈneɪʃəs/; Greek: Ἀθανάσιος Ἀλεξανδρείας, Athanásios Alexandrías; c. 296–298 – 2 May 373), also called Athanasius the Great, Athanasius the Confessor or, primarily in the Coptic Orthodox Church, Athanasius the Apostolic, was the twentieth bishop of Alexandria (as Athanasius I). His episcopate lasted 45 years (c. 8 June 328 – 2 May 373), of which over 17 were spent in five exiles ordered by four different Roman emperors. Athanasius is a renowned Christian theologian, a Church Father, the chief defender of Trinitarianism against Arianism, and a noted Egyptian leader of the fourth century.',\n",
              " \"qg: Cold War, First Gulf War, Kosovo WarSince 1947, Canadian military units have participated in more than 200 operations worldwide, and completed 72 international operations. Canadian soldiers, sailors, and aviators came to be considered world-class professionals through conspicuous service during these conflicts and the country's integral participation in NATO during the Cold War, First Gulf War, Kosovo War, and in United Nations Peacekeeping operations, such as the Suez Crisis, Golan Heights, Cyprus, Croatia, Bosnia, Afghanistan, and Libya. Canada maintained an aircraft carrier from 1957 to 1970 during the Cold War, which never saw combat but participated in patrols during the Cuban Missile Crisis.\",\n",
              " \"qg: BuddhaTibet has various festivals that are commonly performed to worship the Buddha[citation needed] throughout the year. Losar is the Tibetan New Year Festival. Preparations for the festive event are manifested by special offerings to family shrine deities, painted doors with religious symbols, and other painstaking jobs done to prepare for the event. Tibetans eat Guthuk (barley noodle soup with filling) on New Year's Eve with their families. The Monlam Prayer Festival follows it in the first month of the Tibetan calendar, falling between the fourth and the eleventh days of the first Tibetan month. It involves dancing and participating in sports events, as well as sharing picnics. The event was established in 1049 by Tsong Khapa, the founder of the Dalai Lama and the Panchen Lama's order.\",\n",
              " \"qg: 9.3%From 2001 to 2008, Mac sales increased continuously on an annual basis. Apple reported worldwide sales of 3.36 million Macs during the 2009 holiday season. As of Mid-2011, the Macintosh continues to enjoy rapid market share increase in the US, growing from 7.3% of all computer shipments in 2010 to 9.3% in 2011. According to IDC's quarterly PC tracker, globally, in 3rd quarter of 2014, Apple's PC market share increased 5.7 percent year over year, with record sales of 5.5 million units. Apple now sits in the number five spot, with a global market share of about 6% during 2014, behind Lenovo, HP, Dell and Acer.\",\n",
              " 'qg: ImprovisationImprovisation stands at the centre of Chopin\\'s creative processes. However, this does not imply impulsive rambling: Nicholas Temperley writes that \"improvisation is designed for an audience, and its starting-point is that audience\\'s expectations, which include the current conventions of musical form.\" The works for piano and orchestra, including the two concertos, are held by Temperley to be \"merely vehicles for brilliant piano playing ... formally longwinded and extremely conservative\". After the piano concertos (which are both early, dating from 1830), Chopin made no attempts at large-scale multi-movement forms, save for his late sonatas for piano and for cello; \"instead he achieved near-perfection in pieces of simple general design but subtle and complex cell-structure.\" Rosen suggests that an important aspect of Chopin\\'s individuality is his flexible handling of the four-bar phrase as a structural unit.',\n",
              " \"qg: 1861Alfred North Whitehead was born in Ramsgate, Kent, England, in 1861. His father, Alfred Whitehead, was a minister and schoolmaster of Chatham House Academy, a successful school for boys established by Thomas Whitehead, Alfred North's grandfather. Whitehead himself recalled both of them as being very successful schoolmasters, but that his grandfather was the more extraordinary man. Whitehead's mother was Maria Sarah Whitehead, formerly Maria Sarah Buckmaster. Whitehead was apparently not particularly close with his mother, as he never mentioned her in any of his writings, and there is evidence that Whitehead's wife, Evelyn, had a low opinion of her.\",\n",
              " 'qg: 40%While Southeast Asia is rich in flora and fauna, Southeast Asia is facing severe deforestation which causes habitat loss for various endangered species such as orangutan and the Sumatran tiger. Predictions have been made that more than 40% of the animal and plant species in Southeast Asia could be wiped out in the 21st century. At the same time, haze has been a regular occurrence. The two worst regional hazes were in 1997 and 2006 in which multiple countries were covered with thick haze, mostly caused by \"slash and burn\" activities in Sumatra and Borneo. In reaction, several countries in Southeast Asia signed the ASEAN Agreement on Transboundary Haze Pollution to combat haze pollution.',\n",
              " 'qg: Event-based prospective memoriesAnother major way to distinguish different memory functions is whether the content to be remembered is in the past, retrospective memory, or in the future, prospective memory. Thus, retrospective memory as a category includes semantic, episodic and autobiographical memory. In contrast, prospective memory is memory for future intentions, or remembering to remember (Winograd, 1988). Prospective memory can be further broken down into event- and time-based prospective remembering. Time-based prospective memories are triggered by a time-cue, such as going to the doctor (action) at 4pm (cue). Event-based prospective memories are intentions triggered by cues, such as remembering to post a letter (action) after seeing a mailbox (cue). Cues do not need to be related to the action (as the mailbox/letter example), and lists, sticky-notes, knotted handkerchiefs, or string around the finger all exemplify cues that people use as strategies to enhance prospective memory.',\n",
              " 'qg: dragonfly-like formsLate Carboniferous and Early Permian insect orders include both extant groups, their stem groups, and a number of Paleozoic groups, now extinct. During this era, some giant dragonfly-like forms reached wingspans of 55 to 70 cm (22 to 28 in), making them far larger than any living insect. This gigantism may have been due to higher atmospheric oxygen levels that allowed increased respiratory efficiency relative to today. The lack of flying vertebrates could have been another factor. Most extinct orders of insects developed during the Permian period that began around 270 million years ago. Many of the early groups became extinct during the Permian-Triassic extinction event, the largest mass extinction in the history of the Earth, around 252 million years ago.',\n",
              " 'qg: the Shijing or Book of SongsAs a more urban culture developed, academies provided a means of transmission for speculative and philosophical literature in early civilizations, resulting in the prevalence of literature in Ancient China, Ancient India, Persia and Ancient Greece and Rome. Many works of earlier periods, even in narrative form, had a covert moral or didactic purpose, such as the Sanskrit Panchatantra or the Metamorphoses of Ovid. Drama and satire also developed as urban culture provided a larger public audience, and later readership, for literary production. Lyric poetry (as opposed to epic poetry) was often the speciality of courts and aristocratic circles, particularly in East Asia where songs were collected by the Chinese aristocracy as poems, the most notable being the Shijing or Book of Songs. Over a long period, the poetry of popular pre-literate balladry and song interpenetrated and eventually influenced poetry in the literary medium.',\n",
              " \"qg: Olympic PeninsulaSeattle is located between the saltwater Puget Sound (an arm of the Pacific Ocean) to the west and Lake Washington to the east. The city's chief harbor, Elliott Bay, is part of Puget Sound, which makes the city an oceanic port. To the west, beyond Puget Sound, are the Kitsap Peninsula and Olympic Mountains on the Olympic Peninsula; to the east, beyond Lake Washington and the eastside suburbs, are Lake Sammamish and the Cascade Range. Lake Washington's waters flow to Puget Sound through the Lake Washington Ship Canal (consisting of two man-made canals, Lake Union, and the Hiram M. Chittenden Locks at Salmon Bay, ending in Shilshole Bay on Puget Sound).\",\n",
              " 'qg: transported along the canals and riversBy the time of the Uruk period (c. 4100–2900 BC calibrated), the volume of trade goods transported along the canals and rivers of southern Mesopotamia facilitated the rise of many large, stratified, temple-centered cities (with populations of over 10,000 people) where centralized administrations employed specialized workers. It is fairly certain that it was during the Uruk period that Sumerian cities began to make use of slave labor captured from the hill country, and there is ample evidence for captured slaves as workers in the earliest texts. Artifacts, and even colonies of this Uruk civilization have been found over a wide area—from the Taurus Mountains in Turkey, to the Mediterranean Sea in the west, and as far east as central Iran.',\n",
              " 'qg: base aloneThermally, a temperate glacier is at melting point throughout the year, from its surface to its base. The ice of a polar glacier is always below freezing point from the surface to its base, although the surface snowpack may experience seasonal melting. A sub-polar glacier includes both temperate and polar ice, depending on depth beneath the surface and position along the length of the glacier. In a similar way, the thermal regime of a glacier is often described by the temperature at its base alone. A cold-based glacier is below freezing at the ice-ground interface, and is thus frozen to the underlying substrate. A warm-based glacier is above or at freezing at the interface, and is able to slide at this contact. This contrast is thought to a large extent to govern the ability of a glacier to effectively erode its bed, as sliding ice promotes plucking at rock from the surface below. Glaciers which are partly cold-based and partly warm-based are known as polythermal.',\n",
              " \"qg: 1031–1095There are many notable contributors to the field of Chinese science throughout the ages. One of the best examples would be Shen Kuo (1031–1095), a polymath scientist and statesman who was the first to describe the magnetic-needle compass used for navigation, discovered the concept of true north, improved the design of the astronomical gnomon, armillary sphere, sight tube, and clepsydra, and described the use of drydocks to repair boats. After observing the natural process of the inundation of silt and the find of marine fossils in the Taihang Mountains (hundreds of miles from the Pacific Ocean), Shen Kuo devised a theory of land formation, or geomorphology. He also adopted a theory of gradual climate change in regions over time, after observing petrified bamboo found underground at Yan'an, Shaanxi province. If not for Shen Kuo's writing, the architectural works of Yu Hao would be little known, along with the inventor of movable type printing, Bi Sheng (990-1051). Shen's contemporary Su Song (1020–1101) was also a brilliant polymath, an astronomer who created a celestial atlas of star maps, wrote a pharmaceutical treatise with related subjects of botany, zoology, mineralogy, and metallurgy, and had erected a large astronomical clocktower in Kaifeng city in 1088. To operate the crowning armillary sphere, his clocktower featured an escapement mechanism and the world's oldest known use of an endless power-transmitting chain drive.\",\n",
              " 'qg: MechanicalTwo assumptions underpinned the British approach to HAA fire; first, aimed fire was the primary method and this was enabled by predicting gun data from visually tracking the target and having its height. Second, that the target would maintain a steady course, speed and height. This HAA was to engage targets up to 24,000 feet. Mechanical, as opposed to igniferous, time fuses were required because the speed of powder burning varied with height so fuse length was not a simple function of time of flight. Automated fire ensured a constant rate of fire that made it easier to predict where each shell should be individually aimed.',\n",
              " 'qg: The Lamb of GodIn Johannine \"agent Christology\" the submission of Jesus to crucifixion is a sacrifice made as an agent of God or servant of God, for the sake of eventual victory. This builds on the salvific theme of the Gospel of John which begins in John 1:29 with John the Baptist\\'s proclamation: \"The Lamb of God who takes away the sins of the world\". Further reinforcement of the concept is provided in Revelation 21:14 where the \"lamb slain but standing\" is the only one worthy of handling the scroll (i.e. the book) containing the names of those who are to be saved.',\n",
              " 'qg: 2.79There were 46,917 households, out of which 7,835 (16.7%) had children under the age of 18 living in them, 13,092 (27.9%) were opposite-sex married couples living together, 3,510 (7.5%) had a female householder with no husband present, 1,327 (2.8%) had a male householder with no wife present. There were 2,867 (6.1%) unmarried opposite-sex partnerships, and 416 (0.9%) same-sex married couples or partnerships. 22,716 households (48.4%) were made up of individuals and 5,551 (11.8%) had someone living alone who was 65 years of age or older. The average household size was 1.87. There were 17,929 families (38.2% of all households); the average family size was 2.79.',\n",
              " 'qg: urbanThe Baker v. Carr (1962) decision of the US Supreme Court established the principle of \"one man, one vote\", requiring state legislatures to redistrict to bring Congressional apportionment in line with decennial censuses. It also required both houses of state legislatures to be based on population for representation and not geographic districts such as counties. This case arose out of a lawsuit challenging the longstanding rural bias of apportionment of seats in the Tennessee legislature. After decades in which urban populations had been underrepresented in many state legislatures, this significant ruling led to an increased (and proportional) prominence in state politics by urban and, eventually, suburban, legislators and statewide officeholders in relation to their population within the state. The ruling also applied to numerous other states long controlled by rural minorities, such as Alabama, Vermont, and Montana.',\n",
              " 'qg: parentsHome-based manufacturing operations were active year round. Families willingly deployed their children in these income generating home enterprises. In many cases, men worked from home. In France, over 58 percent of garment workers operated out of their homes; in Germany, the number of full-time home operations nearly doubled between 1882 and 1907; and in the United States, millions of families operated out of home seven days a week, year round to produce garments, shoes, artificial flowers, feathers, match boxes, toys, umbrellas and other products. Children aged 5–14 worked alongside the parents. Home-based operations and child labour in Australia, Britain, Austria and other parts of the world was common. Rural areas similarly saw families deploying their children in agriculture. In 1946, Frieda Miller - then Director of United States Department of Labour - told the International Labour Organisation that these home-based operations offered, \"low wages, long hours, child labour, unhealthy and insanitary working conditions.\"',\n",
              " 'qg: the proper aim point automaticallyThe solution was automation, in the form of a mechanical computer, the Kerrison Predictor. Operators kept it pointed at the target, and the Predictor then calculated the proper aim point automatically and displayed it as a pointer mounted on the gun. The gun operators simply followed the pointer and loaded the shells. The Kerrison was fairly simple, but it pointed the way to future generations that incorporated radar, first for ranging and later for tracking. Similar predictor systems were introduced by Germany during the war, also adding radar ranging as the war progressed.',\n",
              " 'qg: Tarsus of CiliciaIn 1045, the Byzantine Empire conquered Bagratid Armenia. Soon, the other Armenian states fell under Byzantine control as well. The Byzantine rule was short lived, as in 1071 Seljuk Turks defeated the Byzantines and conquered Armenia at the Battle of Manzikert, establishing the Seljuk Empire. To escape death or servitude at the hands of those who had assassinated his relative, Gagik II, King of Ani, an Armenian named Roupen, went with some of his countrymen into the gorges of the Taurus Mountains and then into Tarsus of Cilicia. The Byzantine governor of the palace gave them shelter where the Armenian Kingdom of Cilicia was eventually established on 6 January 1198 under King Leo I, a descendant of Prince Roupen.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RSBZXZAI17X",
        "outputId": "1db980d8-0e06-4325-f3a3-4861ab2f2770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     What type of businesses did Nickles want to at...\n",
              "1     To whom did Chopin reveal in letters which par...\n",
              "2     If a species may be harmed, who holds final sa...\n",
              "3     What country has the dog as part of its 12 ani...\n",
              "4                     How long did his episcopate last?\n",
              "5     What are some of the wars the Canadian Militar...\n",
              "6     What is worshipped during Tibet's various fest...\n",
              "7     What was Apples market share of all computer s...\n",
              "8                  What is central to Chopin's process?\n",
              "9                         What year was Whitehead born?\n",
              "10    What percentage of plant and animal species ex...\n",
              "11    If Bob realized he needed to mail his mother a...\n",
              "12        What kind of giant insect form had wingspans?\n",
              "13    What is an example of a collection of classic ...\n",
              "14               What land area is west of Puget Sound?\n",
              "15    How were trade goods transported in southern M...\n",
              "16    From where is the temperature of a glacier mea...\n",
              "17                             When was Shen Kuo alive?\n",
              "18                      What kind of fuses were needed?\n",
              "19                What is another name for Jesus given?\n",
              "20              What was the total average family size?\n",
              "21    Which type of geographical district became mor...\n",
              "22                    Who did the children work beside?\n",
              "23    What did the Predictor calculate after it was ...\n",
              "24                        Where did Roupen find refuge?\n",
              "Name: question, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "# Add padding to have batched tensors with same length\n",
        "inputs = tokenizer(input_txt, \n",
        "                   padding = \"longest\",\n",
        "                   max_length=1024, \n",
        "                   truncation=True, \n",
        "                   return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "8hM-mDIsGT-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate question output\n",
        "outputs = model.generate(input_ids = inputs['input_ids'],\n",
        "                         attention_mask = inputs['attention_mask'])\n",
        "\n",
        "question_output = pprint(tokenizer.batch_decode(outputs, \n",
        "                                                skip_special_tokens=True, \n",
        "                                                clean_up_tokenization_spaces=True\n",
        "                                                )[0], compact=True)\n",
        "\n",
        "question_output"
      ],
      "metadata": {
        "id": "Z69pL7NZGUBd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741832fb-415b-445a-cb79-45164c044de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/generation_tf_utils.py:1695: UserWarning: Neither `max_length` nor `max_new_tokens` have been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'.com..com..com..com..com'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UeZGnimVGUDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T6BHrVRHCMYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tE0mgmNCMax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The T5 model is instructed to perform a particular task by adding a prefix to the start of an input sequence. The prefix for a specific task may be any arbitrary text as long as the same prefix is prepended whenever the model is supposed to execute the given task.\n",
        "\n",
        "Source: https://simpletransformers.ai/docs/t5-specifics/#:~:text=The%20T5%20model%20is%20instructed,to%20execute%20the%20given%20task.&text=binary%20classification"
      ],
      "metadata": {
        "id": "6nhGYMtk8nch"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlUbWlDT7RMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uNvf8ZeXS7_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcE-Jzn6S8CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9l2GCmOFS8Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try two inputs for\n",
        "\n",
        "Source: https://huggingface.co/docs/transformers/model_doc/t5#training"
      ],
      "metadata": {
        "id": "Kt-g_noLS8Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "# import torch\n",
        "\n",
        "# tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "# model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "id": "WyMYoEClMRe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the following 2 hyperparameters are task-specific\n",
        "max_source_length = 1024\n",
        "max_target_length = 500\n",
        "\n",
        "# Suppose we have the following 2 training examples:\n",
        "input_sequence_1 = df.context[0]\n",
        "output_sequence_1 = df.question[0]\n",
        "\n",
        "input_sequence_2 = df.context[6]\n",
        "output_sequence_2 = df.question[6]\n",
        "\n",
        "# encode the inputs\n",
        "task_prefix = \"qg: \"\n",
        "input_sequences = [input_sequence_1, input_sequence_2]\n",
        "\n",
        "encoding = tokenizer(\n",
        "    [task_prefix + sequence for sequence in input_sequences],\n",
        "    padding=\"longest\",\n",
        "    max_length=max_source_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\",\n",
        ")\n",
        "\n",
        "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
        "\n",
        "# encode the targets\n",
        "target_encoding = tokenizer(\n",
        "    [output_sequence_1, output_sequence_2],\n",
        "    padding=\"longest\",\n",
        "    max_length=max_target_length,\n",
        "    truncation=True,\n",
        "    return_tensors=\"tf\",\n",
        ")\n",
        "labels = target_encoding.input_ids\n",
        "\n",
        "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
        "# labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "# forward pass\n",
        "# loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
        "# loss.item()\n",
        "\n",
        "\n",
        "# outputs = model.generate(input_ids = inputs['input_ids'],\n",
        "#                          attention_mask = inputs['attention_mask'])\n",
        "\n",
        "# outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# question_output = pprint(tokenizer.batch_decode(outputs, \n",
        "#                                                 skip_special_tokens=True, \n",
        "#                                                 clean_up_tokenization_spaces=True,\n",
        "#                                                # max_new_tokens=60\n",
        "#                                                 )[0], compact=True)\n",
        "\n",
        "# question_output\n",
        "\n",
        "\n",
        "output_sequences = model.generate(\n",
        "    input_ids=encoding[\"input_ids\"],\n",
        "    attention_mask=encoding[\"attention_mask\"],\n",
        "    do_sample=False,  # disable sampling to test if batching affects output\n",
        "    no_repeat_ngram_size=2,\n",
        ")\n",
        "\n",
        "print(tokenizer.batch_decode(output_sequences, skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4hRhQezLhJV",
        "outputId": "92e8c4c3-ea42-4ae3-c548-d3657323bbfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['. qg: Boeing is the second largest employer in the Seattle area. Boeing was', '. qg:  :::::.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Summary\n",
        "output_sequences = model.generate(input_ids=encoding[\"input_ids\"],\n",
        "                                  attention_mask=encoding[\"attention_mask\"], \n",
        "                              num_beams=1,\n",
        "                              no_repeat_ngram_size=2,\n",
        "                              min_length=10,\n",
        "                              max_length=20)\n",
        "\n",
        "pprint(tokenizer.batch_decode(output_sequences, \n",
        "                              skip_special_tokens=True, \n",
        "                              clean_up_tokenization_spaces=False)[0], \n",
        "       #compact=True\n",
        "       )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3NRCe5mLP2L",
        "outputId": "de34ec70-5267-4902-d243-166ed965dd70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'. qg: Boeing is the second largest employer in the Seattle area. Boeing was'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gv82hZBJLP4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yKXkx6aDLP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E6wSVzOyLP9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prefix: A string indicating the task to perform.\n",
        "\n",
        "input_text: The input text sequence.\n",
        "\n",
        "target_text: The target sequence."
      ],
      "metadata": {
        "id": "xvJMALT7QWT3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4vbeHJtkLQFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ce-ob9U6LQHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IYfzHNmNLQKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBbOlvM0LQMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}